{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bafc561-654b-4e23-a49f-c9fd1a6e43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4a8fe-e042-4861-9b22-7f38059b03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"ai-forever/ruT5-base\"\n",
    ").to(tt.device(\"cuda:0\"))\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ddc5d-fb1b-4859-a1b1-5b339acb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  inp, label = '', ''\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  right_answer = right_answer.replace('\"', \"'\")\n",
    "\n",
    "  inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое название лучше всего подойдёт для этого текста? \"\n",
    "  inp += f'ПРАВИЛЬНЫЙ ОТВЕТ: \"{right_answer}\".'\n",
    "  inp += 'НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: '\n",
    "\n",
    "  options = example[\"options_ru\"]\n",
    "  options = [\n",
    "      option.replace('\"', \"'\") for option in options if option != right_answer\n",
    "  ]\n",
    "  options = [\n",
    "      f'\"{option}\"' for option in options\n",
    "  ]\n",
    "  label = \"; \".join(options)\n",
    "  distractors_len = len(tokenizer(label)[\"input_ids\"])\n",
    "    \n",
    "  return {\n",
    "      \"inp\": inp,\n",
    "      \"distractors\": label,\n",
    "      \"right_answer\": right_answer,\n",
    "      \"distractors_len\": distractors_len\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d6cee-05ee-40a2-9860-f80bc20828e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaa3facfc6e4547b3954cb955491f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47796db166f4bc2bf7b0bdc1f5d0c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7e6519207847718f9d631fe48d80d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"title_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    title_dataset = json.load(inp)\n",
    "\n",
    "(\n",
    "    title_dataset_train,\n",
    "    title_dataset_val,\n",
    "    title_dataset_test\n",
    ") = (\n",
    "    title_dataset[\"train\"],\n",
    "    title_dataset[\"val\"],\n",
    "    title_dataset[\"test\"]\n",
    ")\n",
    "title_dataset_train = Dataset.from_list(title_dataset_train)\n",
    "title_dataset_val = Dataset.from_list(title_dataset_val)\n",
    "title_dataset_test = Dataset.from_list(title_dataset_test)\n",
    "\n",
    "title_dataset_train = title_dataset_train.map(to_new_format)\n",
    "title_dataset_val = title_dataset_val.map(to_new_format)\n",
    "title_dataset_test = title_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4a1ad2-0c8d-4896-bc67-4d60bb9bf7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4375.000000\n",
       "mean       28.631771\n",
       "std         7.996853\n",
       "min        12.000000\n",
       "25%        23.000000\n",
       "50%        27.000000\n",
       "75%        33.000000\n",
       "max       133.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(title_dataset_train[\"distractors_len\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc14da2-fa57-4231-864b-f08608cd7a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = pd.Series(title_dataset_train[\"distractors_len\"]).quantile(0.99)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb6839-a082-4583-8a87-499117ac395b",
   "metadata": {},
   "source": [
    "Evaluate on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d178e98e-e2ea-4328-977f-636dedb14793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_inputs_seq2seq(\n",
    "    input_batch: list[str], #label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    input_batch_ = tokenizer(\n",
    "        input_batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    # label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    # output_length = label_batch_.shape[-1]\n",
    "\n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=MAX_LEN)\n",
    "\n",
    "    output = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in tokenizer.batch_decode(\n",
    "            output_batch)\n",
    "    ]\n",
    "    \n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    # del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505a53c7-8bdd-42ea-8bc5-3b88e95326c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99101/2615775555.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ee0aff4b8e4d94aa335a0698100ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(title_dataset_val) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics_val = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = title_dataset_val[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        output= get_metric_inputs_seq2seq(slice[\"inp\"], model, tokenizer)\n",
    "\n",
    "        distractors = [\n",
    "            item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip()\n",
    "            for item in slice[\"distractors\"]\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            metric = compute_metrics(output, distractors)\n",
    "            metrics_val.append({\n",
    "                \"article\": slice[\"article_ru\"][0],\n",
    "                \"right_answer\": slice[\"right_answer\"][0],\n",
    "                \"distractors\": distractors[0],\n",
    "                \"output\": output[0],\n",
    "    \n",
    "                \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "                \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "                \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "                \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "                \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "                \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "                \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "    \n",
    "                \"article_orig\": slice[\"article\"][0],\n",
    "                \"question_orig\": slice[\"question\"][0],\n",
    "                \"options_orig\": slice[\"options\"][0],\n",
    "                \"right_answer_orig\": slice[\"answer\"][0]\n",
    "            })\n",
    "        except ZeroDivisionError:\n",
    "            metrics_val.append({\n",
    "                \"article\": slice[\"article_ru\"][0],\n",
    "                \"right_answer\": slice[\"right_answer\"][0],\n",
    "                \"distractors\": distractors[0],\n",
    "                \"output\": output[0],\n",
    "    \n",
    "                \"bleu\": 0,\n",
    "                \"sbleu\": 0,\n",
    "                \"rouge1\": 0,\n",
    "                \"rouge2\": 0,\n",
    "                \"rougeL\": 0,\n",
    "                \"rougeLsum\": 0,\n",
    "                \"meteor\": 0,\n",
    "    \n",
    "                \"article_orig\": slice[\"article\"][0],\n",
    "                \"question_orig\": slice[\"question\"][0],\n",
    "                \"options_orig\": slice[\"options\"][0],\n",
    "                \"right_answer_orig\": slice[\"answer\"][0]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a59d6ca-63a6-4c39-82f2-b1b22fca55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val = pd.DataFrame(metrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9a0f10-d215-456c-b4c1-4bb01266bca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>219.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.654926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bleu       sbleu  rouge1  rouge2  rougeL  rougeLsum      meteor\n",
       "count  219.0  219.000000   219.0   219.0   219.0      219.0  219.000000\n",
       "mean     0.0    0.447475     0.0     0.0     0.0        0.0    0.010782\n",
       "std      0.0    0.681609     0.0     0.0     0.0        0.0    0.017403\n",
       "min      0.0    0.000000     0.0     0.0     0.0        0.0    0.000000\n",
       "25%      0.0    0.000000     0.0     0.0     0.0        0.0    0.000000\n",
       "50%      0.0    0.000000     0.0     0.0     0.0        0.0    0.000000\n",
       "75%      0.0    0.823705     0.0     0.0     0.0        0.0    0.021100\n",
       "max      0.0    2.654926     0.0     0.0     0.0        0.0    0.077720"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15eb34cb-21f1-47b9-805a-207c6a29597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val.to_excel(\"T5Metrics-Title-Baseline-val.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53b6b9-912c-431f-9102-8cd1e7adc9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
