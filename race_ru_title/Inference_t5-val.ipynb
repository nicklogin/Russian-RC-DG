{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bafc561-654b-4e23-a49f-c9fd1a6e43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4a8fe-e042-4861-9b22-7f38059b03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"RuT5-RACE-title-1/checkpoint-87500\"\n",
    ").to(tt.device(\"cuda:0\"))\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ddc5d-fb1b-4859-a1b1-5b339acb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  inp, label = '', ''\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  right_answer = right_answer.replace('\"', \"'\")\n",
    "\n",
    "  inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое название лучше всего подойдёт для этого текста? \"\n",
    "  inp += f'ПРАВИЛЬНЫЙ ОТВЕТ: \"{right_answer}\".'\n",
    "  inp += 'НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: '\n",
    "\n",
    "  options = example[\"options_ru\"]\n",
    "  options = [\n",
    "      option.replace('\"', \"'\") for option in options if option != right_answer\n",
    "  ]\n",
    "  options = [\n",
    "      f'\"{option}\"' for option in options\n",
    "  ]\n",
    "  label = \"; \".join(options)\n",
    "  distractors_len = len(tokenizer(label)[\"input_ids\"])\n",
    "    \n",
    "  return {\n",
    "      \"inp\": inp,\n",
    "      \"distractors\": label,\n",
    "      \"right_answer\": right_answer,\n",
    "      \"distractors_len\": distractors_len\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d6cee-05ee-40a2-9860-f80bc20828e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441fdb37bcd2449cbe0dd66e27ebec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc0e28c299e4ed1b2d5e85124b08576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935eea78caa442f68775603216eea941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"title_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    title_dataset = json.load(inp)\n",
    "\n",
    "(\n",
    "    title_dataset_train,\n",
    "    title_dataset_val,\n",
    "    title_dataset_test\n",
    ") = (\n",
    "    title_dataset[\"train\"],\n",
    "    title_dataset[\"val\"],\n",
    "    title_dataset[\"test\"]\n",
    ")\n",
    "title_dataset_train = Dataset.from_list(title_dataset_train)\n",
    "title_dataset_val = Dataset.from_list(title_dataset_val)\n",
    "title_dataset_test = Dataset.from_list(title_dataset_test)\n",
    "\n",
    "title_dataset_train = title_dataset_train.map(to_new_format)\n",
    "title_dataset_val = title_dataset_val.map(to_new_format)\n",
    "title_dataset_test = title_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4a1ad2-0c8d-4896-bc67-4d60bb9bf7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4375.000000\n",
       "mean       28.631771\n",
       "std         7.996853\n",
       "min        12.000000\n",
       "25%        23.000000\n",
       "50%        27.000000\n",
       "75%        33.000000\n",
       "max       133.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(title_dataset_train[\"distractors_len\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc14da2-fa57-4231-864b-f08608cd7a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = pd.Series(title_dataset_train[\"distractors_len\"]).quantile(0.99)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb6839-a082-4583-8a87-499117ac395b",
   "metadata": {},
   "source": [
    "Evaluate on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d178e98e-e2ea-4328-977f-636dedb14793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_inputs_seq2seq(\n",
    "    input_batch: list[str], #label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    input_batch_ = tokenizer(\n",
    "        input_batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    # label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    # output_length = label_batch_.shape[-1]\n",
    "\n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=MAX_LEN)\n",
    "\n",
    "    output = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in tokenizer.batch_decode(\n",
    "            output_batch)\n",
    "    ]\n",
    "    \n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    # del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505a53c7-8bdd-42ea-8bc5-3b88e95326c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95500/802532084.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437452d3deb54837899d99288a6ef665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(title_dataset_val) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics_val = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = title_dataset_val[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        output= get_metric_inputs_seq2seq(slice[\"inp\"], model, tokenizer)\n",
    "\n",
    "        distractors = [\n",
    "            item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip()\n",
    "            for item in slice[\"distractors\"]\n",
    "        ]\n",
    "\n",
    "        metric = compute_metrics(output, distractors)\n",
    "\n",
    "        # код далее подходит только для батчей из одиночных примеров (BATCH_SIZE=1):\n",
    "        metrics_val.append({\n",
    "            \"article\": slice[\"article_ru\"][0],\n",
    "            \"right_answer\": slice[\"right_answer\"][0],\n",
    "            \"distractors\": distractors[0],\n",
    "            \"output\": output[0],\n",
    "\n",
    "            \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "            \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "            \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "            \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "            \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "            \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "            \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "\n",
    "            \"article_orig\": slice[\"article\"][0],\n",
    "            \"question_orig\": slice[\"question\"][0],\n",
    "            \"options_orig\": slice[\"options\"][0],\n",
    "            \"right_answer_orig\": slice[\"answer\"][0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28dc9a4-5d32-401c-97bb-ca7a4faaf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val = pd.DataFrame(metrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e898007b-6574-4bc9-8306-3c254ff7c750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.166844</td>\n",
       "      <td>23.326224</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.460947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248130</td>\n",
       "      <td>20.969813</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>0.054059</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>0.180878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.903650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.879863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.918539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.220685</td>\n",
       "      <td>22.068529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bleu       sbleu      rouge1      rouge2      rougeL   rougeLsum  \\\n",
       "count  219.000000  219.000000  219.000000  219.000000  219.000000  219.000000   \n",
       "mean     0.166844   23.326224    0.013807    0.003653    0.013807    0.013807   \n",
       "std      0.248130   20.969813    0.104649    0.054059    0.104649    0.104649   \n",
       "min      0.000000    5.903650    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   12.879863    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   15.918539    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.220685   22.068529    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000  100.000000    1.000000    0.800000    1.000000    1.000000   \n",
       "\n",
       "           meteor  \n",
       "count  219.000000  \n",
       "mean     0.460947  \n",
       "std      0.180878  \n",
       "min      0.173077  \n",
       "25%      0.347434  \n",
       "50%      0.433073  \n",
       "75%      0.528507  \n",
       "max      0.999981  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb975bae-b25f-426f-aac8-5b1223ba6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val.to_excel(\"T5Metrics-Title-val.xlsx\", engine=\"openpyxl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
