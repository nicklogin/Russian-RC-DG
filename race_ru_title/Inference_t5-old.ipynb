{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bafc561-654b-4e23-a49f-c9fd1a6e43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4a8fe-e042-4861-9b22-7f38059b03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model_best = T5ForConditionalGeneration.from_pretrained(\"Ru-RACE-T5-title-best\").to(tt.device(\"cuda:0\"))\n",
    "model_last = T5ForConditionalGeneration.from_pretrained(\"RuT5-RACE-title/checkpoint-87500\").to(tt.device(\"cuda:0\"))\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ddc5d-fb1b-4859-a1b1-5b339acb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  inp, label = '', ''\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "  inp += example['article_ru'] + \"\\n\" + \"ВОПРОС: Какое название лучше всего подойдёт для этого текста? \"\n",
    "  inp += f\"ПРАВИЛЬНЫЙ ОТВЕТ: {right_answer}\"\n",
    "  inp += \"\\nНЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\\n\"\n",
    "  for option in example[\"options_ru\"]:\n",
    "      if option != right_answer:\n",
    "          label += f\"\\n  {option}\"\n",
    "  return {\"inp\": inp, \"distractors\": label, \"right_answer\": right_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d6cee-05ee-40a2-9860-f80bc20828e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a983e0c4df4c82834aaef8a31e4fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ca107d723c4beeb20dd5bd2beaf999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f049219366458fb96f54b0342b9685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"title_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    title_dataset = json.load(inp)\n",
    "\n",
    "title_dataset_train, title_dataset_val, title_dataset_test = title_dataset[\"train\"], title_dataset[\"val\"], title_dataset[\"test\"]\n",
    "title_dataset_train = Dataset.from_list(title_dataset_train)\n",
    "title_dataset_val = Dataset.from_list(title_dataset_val)\n",
    "title_dataset_test = Dataset.from_list(title_dataset_test)\n",
    "\n",
    "title_dataset_train = title_dataset_train.map(to_new_format)\n",
    "title_dataset_val = title_dataset_val.map(to_new_format)\n",
    "title_dataset_test = title_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb6839-a082-4583-8a87-499117ac395b",
   "metadata": {},
   "source": [
    "Evaluate on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9f2bbd-192c-4e6c-b09a-cadb9685135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e7dc90c0f24b04ac532229c9811d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e183d4ad3748d8b3956a2bbe743f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b94a3fca7f406596ba7fe7014a4eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"inp\"]\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"distractors\"]\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "title_dataset_train = title_dataset_train.map(preprocess_function, batched=True, batch_size=2)\n",
    "title_dataset_val = title_dataset_val.map(preprocess_function, batched=True, batch_size=2)\n",
    "title_dataset_test = title_dataset_test.map(preprocess_function, batched=True, batch_size=2)\n",
    "\n",
    "\n",
    "BATCH_SIZE  = 1\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "MODEL_NAME=\"RuT5-RACE-title-eval\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    # evaluation_strategy=\"steps\", eval_steps=100, save_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    prediction_loss_only=False,\n",
    "    gradient_checkpointing=True,\n",
    "    predict_with_generate=True, fp16=True,\n",
    "    eval_accumulation_steps=1\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metric_values(output: list[str], label_batch: list[str]) -> dict[str, Any]:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict\n",
    "\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict[str, Any]:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels > 0, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    print(len(preds), len(labels))\n",
    "\n",
    "    preds = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in preds\n",
    "    ]\n",
    "    labels = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in labels\n",
    "    ]\n",
    "\n",
    "    metrics = compute_metric_values(preds, labels)\n",
    "    metric_dict = {\n",
    "        \"bleu\": metrics[\"bleu\"][\"bleu\"],\n",
    "        \"sbleu\": metrics[\"sbleu\"][\"score\"],\n",
    "        \"rouge1\": metrics[\"rouge\"][\"rouge1\"],\n",
    "        \"rouge2\": metrics[\"rouge\"][\"rouge2\"],\n",
    "        \"rougeL\": metrics[\"rouge\"][\"rougeL\"],\n",
    "        \"rougeLsum\": metrics[\"rouge\"][\"rougeLsum\"],\n",
    "        \"meteor\": metrics[\"meteor\"][\"meteor\"]\n",
    "    }\n",
    "    return metric_dict\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_last, padding=True)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_last,\n",
    "    args,\n",
    "    train_dataset=title_dataset_train,\n",
    "    eval_dataset=title_dataset_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45abc2f-ec32-4314-a259-24f853b2a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='461' max='219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [219/219 08:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.688899040222168,\n",
       " 'eval_bleu': 0.07925729794697821,\n",
       " 'eval_sbleu': 7.925729794697821,\n",
       " 'eval_rouge1': 0.008480104370515329,\n",
       " 'eval_rouge2': 0.0036529680365296807,\n",
       " 'eval_rougeL': 0.008480104370515329,\n",
       " 'eval_rougeLsum': 0.008480104370515329,\n",
       " 'eval_meteor': 0.15350119191112346,\n",
       " 'eval_runtime': 113.4037,\n",
       " 'eval_samples_per_second': 1.931,\n",
       " 'eval_steps_per_second': 1.931}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b10fc3-10dd-49d0-bc73-8dc41030f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.64674186706543,\n",
       " 'eval_bleu': 0.06429751741731445,\n",
       " 'eval_sbleu': 6.429751741731442,\n",
       " 'eval_rouge1': 0.012734785875281741,\n",
       " 'eval_rouge2': 0.0013774104683195595,\n",
       " 'eval_rougeL': 0.012734785875281741,\n",
       " 'eval_rougeLsum': 0.012797395442023539,\n",
       " 'eval_meteor': 0.14833763487535995,\n",
       " 'eval_runtime': 143.9518,\n",
       " 'eval_samples_per_second': 1.681,\n",
       " 'eval_steps_per_second': 1.681}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ef34ff-7fc6-42b3-9690-79518901ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='461' max='219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [219/219 03:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.082942008972168,\n",
       " 'eval_bleu': 0.01303553961201627,\n",
       " 'eval_sbleu': 1.303553961201627,\n",
       " 'eval_rouge1': 0.0,\n",
       " 'eval_rouge2': 0.0,\n",
       " 'eval_rougeL': 0.0,\n",
       " 'eval_rougeLsum': 0.0,\n",
       " 'eval_meteor': 0.064937282371549,\n",
       " 'eval_runtime': 103.8302,\n",
       " 'eval_samples_per_second': 2.109,\n",
       " 'eval_steps_per_second': 2.109}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_best, padding=True)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_best,\n",
    "    args,\n",
    "    train_dataset=title_dataset_train,\n",
    "    eval_dataset=title_dataset_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabe693b-13a7-40a4-9fa3-b990f5161d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.0236856937408447,\n",
       " 'eval_bleu': 0.015322439643502146,\n",
       " 'eval_sbleu': 1.532243964350215,\n",
       " 'eval_rouge1': 0.004820936639118457,\n",
       " 'eval_rouge2': 0.0,\n",
       " 'eval_rougeL': 0.004132231404958678,\n",
       " 'eval_rougeLsum': 0.004132231404958678,\n",
       " 'eval_meteor': 0.08073514475478905,\n",
       " 'eval_runtime': 119.6661,\n",
       " 'eval_samples_per_second': 2.022,\n",
       " 'eval_steps_per_second': 2.022}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31a9d34-3a7d-4935-b715-490af7b63f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(text: str, model: PreTrainedModel) -> str:\n",
    "    input_ = tokenizer([text], return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    )\n",
    "    return tokenizer.batch_decode(output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab0fc91-1bcb-415b-8f68-42f4b83c02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В 70-е годы Организация Объединенных Наций организовала несколько важных совещаний по проблемам окружающей человека среды для изучения весьма серьезной проблемы. Мы, люди, уничтожаем мир вокруг нас. Мы должны научиться защищать их, иначе жизнь будет очень плохой для наших детей и внуков.\n",
      "Эта проблема имеет несколько важных аспектов.\n",
      "Население\n",
      "Большинство проблем окружающей среды связано с ростом численности населения. В 1700 году в мире насчитывалось 635 миллионов человек; в 1900 году их было 1,6 миллиарда; в 1950 году - 2,5 миллиарда; и в 1980 году - 4,4 миллиарда. В 2010 году будет 7,3 миллиарда человек, больше людей нуждаются в воде, большем количестве продуктов питания, большем количестве древесины и большем количестве нефти.\n",
      "Распределение\n",
      "Ученые говорят, что в мире достаточно воды для всех, но в некоторых странах много воды, а в некоторых только немного. Некоторые районы получают весь дождь в течение одного сезона. Остальная часть года суха.\n",
      "Нефтепродукты\n",
      "Мы используем нефть в мире. Мы используем ее в наших автомобилях и нагреваем наши здания зимой. Армены используют нефтехимические вещества для обогащения почвы. Они используют их для убийства насекомых на этих растениях. Эти химикаты попадают в реки и озера и убивают рыбу. Тысячи людей также умирают от этих химических веществ каждый год. Химические вещества также попадают в воздух и загрязняют его. Винды перевозят этот загрязненный воздух в другие страны и другие страны.\n",
      "Нищета\n",
      "Бедные фермеры используют одну и ту же землю снова и снова. Земля нуждается в отдыхе, так что она будет лучше в следующем году. Однако фермер должен иметь еду каждый год. Бедные люди срубают деревья для дров. В некоторых районах, когда деревья исчезают, земля превращается в пустыню. В то же время, люди нуждаются в дереве для приготовления пищи сейчас. Бедные люди не могут сохранить окружающую среду для будущего.\n",
      "Теперь у нас есть информация и способность решать эти огромные проблемы. Однако это не проблема для одной страны или одной части мира. Это проблема для всех людей. Народ и нация мира должны работать сообща для защиты мировых ресурсов. Никто не контролирует будущее, но мы все помогаем ему.\n",
      "ВОПРОС: Какое название лучше всего подойдёт для этого текста? ПРАВИЛЬНЫЙ ОТВЕТ: Сохранение мировых природных ресурсов\n",
      "НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title_dataset_test[42][\"inp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff58be34-a643-490d-96c4-f2770bbda765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Разрушенный мир\n",
      "  Серьезная проблема, на которую нам следует обратить внимание\n",
      "  Аспекты, которые разрушили наш мир\n"
     ]
    }
   ],
   "source": [
    "print(title_dataset_test[42][\"distractors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f754c2-9ccd-4db8-985d-675aa698a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Как защитить окружающую среду Как защитить окружающую среду Как защитить окружающую среду</s>\n"
     ]
    }
   ],
   "source": [
    "predict_model_best = model_predict(title_dataset_test[42][\"inp\"], model_best)\n",
    "print(predict_model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "839587a5-d8c8-41e1-91b8-6c06dcdd16e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Как защитить окружающую среду Глобальная проблема Как защитить окружающую среду</s>\n"
     ]
    }
   ],
   "source": [
    "predict_model_last = model_predict(title_dataset_test[42][\"inp\"], model_last)\n",
    "print(predict_model_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e6d37f-d061-44f0-bea1-9fdb351726b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Говорящие растения могут звучать как персонажи в сказке. Но недавние научные исследования показали, что растения общаются друг с другом и с другими живыми существами удивительно многими способами. Чтобы понять их, ученые говорят, нам просто нужно выучить их язык. Фермеры особенно заинтересованы в том, что говорят растения.\n",
      "\"Планты могут общаться со всеми видами организмов. Они могут общаться с гигантскими бактериями, другими растениями и насекомыми. Они делают это химически, - сказал Кахилл, профессор экологии Университета Альберты в Канаде.\n",
      "Ученые-растители только начинают понимать этот химический \"язык\". Кейхил говорит, что исследования показали, например, что растения могут оценивать состояние окружающей их среды и принимать соответствующие меры.  Растения способны, например, сигнализировать боль или дискомфорт, вызываемые чем-либо от экстремальных температур до насекомого. Джек Шульц, профессор химической экологии Миссурийского университета, говорит, что, когда растение чувствует, что его съедают, оно не может уйти от неприятностей; напротив, оно выпустит химический пар, который - другие растения поблизости.\n",
      "«Их язык — химический язык, и он включает химикаты, которые движутся через воздух и легко поддаются изменению, и, главным образом, это запахи, с которыми мы знакомы», — объяснил Шульц.\n",
      "«Все растения отреагировали на атаку, изменив свою химию, чтобы защитить себя», — напомнил Шульц. \"Но мы были весьма удивлены, обнаружив, что близлежащие растения также изменили свою химию, чтобы защитить себя, хотя они и не были частью эксперимента\".\n",
      "Исследования также показали, что растения, подвергшиеся нападению, выделяют приятные химикаты. Эти химикаты привлекают дружелюбных насекомых, которые нападают на вредителей, питающихся растениями.\n",
      "В конце концов, способность растений сообщать о своих потребностях - и наша способность понимать их - может помочь фермерам сократить использование ядовитых химических веществ, сократить эксплуатационные издержки и ограничить ущерб окружающей среде.\n",
      "ВОПРОС: Какое название лучше всего подойдёт для этого текста? ПРАВИЛЬНЫЙ ОТВЕТ: Растения могут говорить\n",
      "НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(title_dataset_test[100][\"inp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2243a7-765e-4eb0-b878-02b99a9aee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Связь между растениями\n",
      "  Химический \"Language\"\n",
      "  Как растения защищают себя\n"
     ]
    }
   ],
   "source": [
    "print(title_dataset_test[100][\"distractors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de933df-0f05-4a50-8ad7-c05a6bc11c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Растения и люди Растения и люди Растения и люди</s>\n"
     ]
    }
   ],
   "source": [
    "predict_model_best = model_predict(title_dataset_test[100][\"inp\"], model_best)\n",
    "print(predict_model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "979b414b-cdeb-4d86-a363-9df4ab25ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Волшебный язык Растения могут общаться Растения могут говорить</s>\n"
     ]
    }
   ],
   "source": [
    "predict_model_last = model_predict(title_dataset_test[100][\"inp\"], model_last)\n",
    "print(predict_model_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d178e98e-e2ea-4328-977f-636dedb14793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_inputs_seq2seq(\n",
    "    input_batch: list[str], #label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    input_batch_ = tokenizer(input_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    # label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    # output_length = label_batch_.shape[-1]\n",
    "\n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_)\n",
    "\n",
    "    output = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in tokenizer.batch_decode(output_batch)\n",
    "    ]\n",
    "    \n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    # del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae179de2-929f-4df7-adf6-d17318117596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = title_dataset_test[\"inp\"][:16]\n",
    "right_answers = title_dataset_test[\"right_answer\"][:16]\n",
    "labels = [item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip() for item in title_dataset_test[\"distractors\"][:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d727f17-ee18-4171-b071-aa76bc18c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model_best = get_metric_inputs_seq2seq(model_inputs, model_best, tokenizer)\n",
    "predict_model_last = get_metric_inputs_seq2seq(model_inputs, model_last, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd7c8153-42be-4533-ba00-6fab71357fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Формы сложных слов. Как пользоваться смешающими словами. Водонепроницаемый Клот в лучшем.',\n",
       " 'Отец Рождество опасен? Истинная история Святого Николая Традиции Рождества',\n",
       " 'Истории о некоторых пациентах с гипертонией. Рассказ может помочь снизить кровяное давление. Предложения о том, как снизить кровяное давление.',\n",
       " 'Как хорошо проводить время Благотворительные мероприятия во всем мире Выступления суперзвезд на благотворительных мероприятиях',\n",
       " 'Неприятный друг Два невероятных случая Удар по стене',\n",
       " 'Есть шансы, что они попытаются их схватить. Справляйтесь с несчастьем, будучи предопределённым. Лучший способ познать себя, выбрать бездомность',\n",
       " 'Что означает три выстрела и два выстрела в лесу Как найти своих друзей, когда ты заблудился в лесу Самое важное — оставаться в одном месте',\n",
       " 'Найти дом Жить с семьей Лучший приют',\n",
       " 'Человек с Марса Что-то о коробках Футбольная игра',\n",
       " 'Австралия, известная своим культурным разнообразием Австралия -- дом спорта Австралия -- фантастическая природная среда',\n",
       " 'Измени свои привычки Экономьте энергию Пик с температурой и энергией',\n",
       " 'Преимущества и недостатки онлайнового обучения Обучение в онлайновом режиме по сравнению с обучением в классе Как выжить в век информации',\n",
       " 'Женщины держат половину Неба Ужасный опыт Не судите по внешности',\n",
       " 'Берегите себя, черные. Скажи \"нет\" уезжающим. Скажи \"нет\" высокому кровяному давлению.',\n",
       " 'История Нового года. Куда отпраздновать канун Нового года. 12 винограда, 12 месяцев.',\n",
       " 'Символ Розы Любовь слепа Не суди книгу по ее обложке']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d11300-92a9-4c39-b824-f206a0ba0b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Как быть хорошим человеком Как быть хорошим человеком Как быть хорошим человеком',\n",
       " 'Как Санта Клаус навещает своих детей Как Санта Клаус помогает бедным девушкам',\n",
       " 'Как быть здоровым. Как быть здоровым. Как быть здоровым.',\n",
       " 'Фестиваль Гластонбери в Великобритании Популярный фестиваль Гластонбери в Великобритании Популярный фестиваль',\n",
       " 'Незабываемый опыт Незабываемый опыт Незабываемый опыт',\n",
       " 'Как стать лучшим учеником Гарвардского университета Как стать лучшим студентом Гарвардского университета',\n",
       " 'Как найти друзей Как найти друзей Как найти друзей',\n",
       " 'Как жить с родителями Как жить с родителями Как жить с родителями',\n",
       " 'Как жить на Марсе Как жить на Марсе Как жить на Марсе',\n",
       " 'Австралийцы - лучшие спортсмены в мире Австралийцы -',\n",
       " 'Как экономить энергию Постарайся быть энергичным. Как экономить энергию',\n",
       " 'Развитие информационных технологий Развитие Интернета Развитие Интернета',\n",
       " 'Мальчик и его мать Мальчик и его мать Мальчик и его мать',\n",
       " 'Как есть. Как есть. Как есть.',\n",
       " 'Новый год - это праздник для детей. Новый год - это праздник для детей. Новый год -',\n",
       " 'Любовь к девушке Любовь к девушке Любовь к девушке']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf004405-e3ff-4ef6-a384-c22aa75b8c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Как хорошо одеваться Особая одежда в Англии Хорошая одежда и плохая одежда',\n",
       " 'Отец Рождество спас троих девочек. Легенда Санта Клауса',\n",
       " 'Как справиться с кровяным давлением. Как справляться с кровяным давлением. Как сохранять здоровье',\n",
       " 'Рождественские фестивальы в Великобритании Большая помощь <unk> lt; <unk>lt; Гластон',\n",
       " 'Удар по стене Два особых случая Удар по стене',\n",
       " 'Лучший способ получить стипендию Гарвард -- город для молодых студентов Жизнь в колледже',\n",
       " 'Путешествовать в лесу Что делать, если ты потеряешься? Как помочь другим',\n",
       " 'Держаться подальше от мира Живи в убежищнице, ищи его. В',\n",
       " 'Человек с Марса Жизнь на Марсе Интересная планета',\n",
       " 'Климат в Австралии -- самый теплый и мягкий в мире Австралийцы -- мечта',\n",
       " 'Измени свои привычки Экономьте энергию Печь с температурой и энергией',\n",
       " 'Развитие информационной технологии История Интернета Информация в будущем',\n",
       " 'В жаркое лето Страшный крокодил Опасность',\n",
       " 'Ущерб, причиненный слишком большим количеством соли Здоровые и нездоровые привычки питания С',\n",
       " 'Изменения в новом году. Радость нового года. Различия между старым и новым.',\n",
       " 'Совещание на станции Девушка с розой Солдат и девочка']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecba4301-9983-4035-a63f-bb28146f6964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Связанные слова в повседневной жизни',\n",
       " 'Легенда Санта-Клауса',\n",
       " 'Лечение кровяного давления.',\n",
       " 'Фестиваль Гластонбери',\n",
       " 'Доброта незнакомцев',\n",
       " 'От скамейки в парке до Гарвардского общежития Потрясающая история',\n",
       " 'Что делать, если ты потеряешься в лесу',\n",
       " 'Уход из дома',\n",
       " 'Письмо с Марса',\n",
       " 'Австралия -- самое живое место в мире',\n",
       " 'Ежедневный энергетический цикл',\n",
       " 'Образование в информационном возрасте',\n",
       " 'Шрамы любви',\n",
       " 'Смотри за солью.',\n",
       " 'Радость Нового года по всему миру.',\n",
       " 'Испытание любви']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5218caca-aca9-4f9e-af57-fce24626ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': {'bleu': 0.0,\n",
       "  'precisions': [0.0872093023255814, 0.00641025641025641, 0.0, 0.0],\n",
       "  'brevity_penalty': 0.7014180812626855,\n",
       "  'length_ratio': 0.7381974248927039,\n",
       "  'translation_length': 172,\n",
       "  'reference_length': 233},\n",
       " 'sbleu': {'score': 0.558697314056591,\n",
       "  'counts': [15, 1, 0, 0],\n",
       "  'totals': [172, 156, 140, 124],\n",
       "  'precisions': [8.720930232558139,\n",
       "   0.6410256410256411,\n",
       "   0.35714285714285715,\n",
       "   0.20161290322580644],\n",
       "  'bp': 0.7014180812626855,\n",
       "  'sys_len': 172,\n",
       "  'ref_len': 233},\n",
       " 'rouge': {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0},\n",
       " 'meteor': {'meteor': 0.045494441084467666}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(predict_model_best, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618eb678-10af-411b-b1e2-34bf3a086bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': {'bleu': 0.057582524419918166,\n",
       "  'precisions': [0.21978021978021978,\n",
       "   0.0963855421686747,\n",
       "   0.05333333333333334,\n",
       "   0.029850746268656716],\n",
       "  'brevity_penalty': 0.7556176533910264,\n",
       "  'length_ratio': 0.7811158798283262,\n",
       "  'translation_length': 182,\n",
       "  'reference_length': 233},\n",
       " 'sbleu': {'score': 5.758252441991816,\n",
       "  'counts': [40, 16, 8, 4],\n",
       "  'totals': [182, 166, 150, 134],\n",
       "  'precisions': [21.978021978021978,\n",
       "   9.63855421686747,\n",
       "   5.333333333333333,\n",
       "   2.985074626865672],\n",
       "  'bp': 0.7556176533910264,\n",
       "  'sys_len': 182,\n",
       "  'ref_len': 233},\n",
       " 'rouge': {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0},\n",
       " 'meteor': {'meteor': 0.176320067393745}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(predict_model_last, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07511fd2-18f9-4ce0-8d0a-d00a1c0a70b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7813/2437664213.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd79c980ab3d4ee8befc72a79fd58ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(title_dataset_test) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = title_dataset_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        output_best = get_metric_inputs_seq2seq(slice[\"inp\"], model_best, tokenizer)\n",
    "        output_last = get_metric_inputs_seq2seq(slice[\"inp\"], model_last, tokenizer)\n",
    "\n",
    "        distractors = [item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip() for item in slice[\"distractors\"]]\n",
    "\n",
    "        metrics_best = compute_metrics(output_best, distractors)\n",
    "        metrics_last = compute_metrics(output_last, distractors)\n",
    "\n",
    "        # код далее подходит только для батчей из одиночных примеров (BATCH_SIZE=1):\n",
    "        metrics.append({\n",
    "            \"article\": slice[\"article_ru\"][0],\n",
    "            \"right_answer\": slice[\"right_answer\"][0],\n",
    "            \"distractors\": distractors[0],\n",
    "            \"output_best\": output_best[0],\n",
    "            \"output_last\": output_last[0],\n",
    "\n",
    "            \"bleu_best\": metrics_best[\"bleu\"][\"bleu\"],\n",
    "            \"sbleu_best\": metrics_best[\"sbleu\"][\"score\"],\n",
    "            \"rouge1_best\": metrics_best[\"rouge\"][\"rouge1\"],\n",
    "            \"rouge2_best\": metrics_best[\"rouge\"][\"rouge2\"],\n",
    "            \"rougeL_best\": metrics_best[\"rouge\"][\"rougeL\"],\n",
    "            \"rougeLsum_best\": metrics_best[\"rouge\"][\"rougeLsum\"],\n",
    "            \"meteor_best\": metrics_best[\"meteor\"][\"meteor\"],\n",
    "\n",
    "            \"bleu_last\": metrics_last[\"bleu\"][\"bleu\"],\n",
    "            \"sbleu_last\": metrics_last[\"sbleu\"][\"score\"],\n",
    "            \"rouge1_last\": metrics_last[\"rouge\"][\"rouge1\"],\n",
    "            \"rouge2_last\": metrics_last[\"rouge\"][\"rouge2\"],\n",
    "            \"rougeL_last\": metrics_last[\"rouge\"][\"rougeL\"],\n",
    "            \"rougeLsum_last\": metrics_last[\"rouge\"][\"rougeLsum\"],\n",
    "            \"meteor_last\": metrics_last[\"meteor\"][\"meteor\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "203bc33a-e8d9-47e9-9f10-c06f4993f6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'Девушка с голубыми глазами - голубоглазый. Мужчина с длинными ногами - это человек с длинными ногами. Женщина с белыми волосами - женщина с белыми волосами. Дети, у которых хорошая внешность, красивые дети. Что ты делаешь, когда хочешь купить одежду? Ты идешь в магазин. Если ты найдёшь одежду подходящего размера для тебя, и если она будет готова, ты, вероятно, купишь ее. Их называют готовой одеждой. Если вы не сможете найти одежду того размера, вы пойдёте в портной. Портной - это человек, который делает одежду. Он измерит вас тщательно, а потом сделает для вас одеяние. Такая одежда называется ручной одеждой.\\nКак мы называем человека, который плохо одет? Мы называем его плохо одетым человеком. Женщина, хорошо одетая, называется хорошо одетая женщина.\\nЧто ты носишь, когда идет сильный дождь? Ты носишь пальто, которое удержит дождь. Такое пальто называется плащом. Она сделана из водонепроницаемой ткани - зуб, который не позволяет воде пройти. В Англии много дождя. Если приедешь в Англию, принеси плащ и зонтик. Ты найдешь их полезными.\\nЕсли пол, стены и потолок комнаты сделаны таким образом, чтобы звук не мог пройти через стену, то мы говорим, что комната звуконепроницаема. На всех радиостанциях имеются звуконепроницаемые комнаты.',\n",
       " 'right_answer': 'Связанные слова в повседневной жизни',\n",
       " 'distractors': 'Формы сложных слов. Как пользоваться смешающими словами. Водонепроницаемый Клот в лучшем.',\n",
       " 'output_best': 'Как быть хорошим человеком Как быть хорошим человеком Как быть хорошим человеком',\n",
       " 'output_last': 'Как хорошо одеваться Особая одежда в Англии Хорошая одежда и плохая одежда',\n",
       " 'bleu_best': 0.0,\n",
       " 'sbleu_best': 2.8666091494718775,\n",
       " 'rouge1_best': 0.0,\n",
       " 'rouge2_best': 0.0,\n",
       " 'rougeL_best': 0.0,\n",
       " 'rougeLsum_best': 0.0,\n",
       " 'meteor_best': 0.036231884057971016,\n",
       " 'bleu_last': 0.0,\n",
       " 'sbleu_last': 3.4089919964838553,\n",
       " 'rouge1_last': 0.0,\n",
       " 'rouge2_last': 0.0,\n",
       " 'rougeL_last': 0.0,\n",
       " 'rougeLsum_last': 0.0,\n",
       " 'meteor_last': 0.07246376811594203}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0aaa914-2a22-49bb-818f-e22c1d469b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3daf446-bcf0-45e5-8221-c0fa0af118c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_best</th>\n",
       "      <th>sbleu_best</th>\n",
       "      <th>rouge1_best</th>\n",
       "      <th>rouge2_best</th>\n",
       "      <th>rougeL_best</th>\n",
       "      <th>rougeLsum_best</th>\n",
       "      <th>meteor_best</th>\n",
       "      <th>bleu_last</th>\n",
       "      <th>sbleu_last</th>\n",
       "      <th>rouge1_last</th>\n",
       "      <th>rouge2_last</th>\n",
       "      <th>rougeL_last</th>\n",
       "      <th>rougeLsum_last</th>\n",
       "      <th>meteor_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.0</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004497</td>\n",
       "      <td>3.117486</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.080099</td>\n",
       "      <td>0.048083</td>\n",
       "      <td>7.797526</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.148944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033097</td>\n",
       "      <td>4.202345</td>\n",
       "      <td>0.053462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053462</td>\n",
       "      <td>0.053462</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>0.167598</td>\n",
       "      <td>16.228023</td>\n",
       "      <td>0.093211</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.093211</td>\n",
       "      <td>0.093211</td>\n",
       "      <td>0.209340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.236216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.449032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.089055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.047310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.714697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.331808</td>\n",
       "      <td>33.180774</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bleu_best  sbleu_best  rouge1_best  rouge2_best  rougeL_best  \\\n",
       "count  242.000000  242.000000   242.000000        242.0   242.000000   \n",
       "mean     0.004497    3.117486     0.004821          0.0     0.004821   \n",
       "std      0.033097    4.202345     0.053462          0.0     0.053462   \n",
       "min      0.000000    0.000000     0.000000          0.0     0.000000   \n",
       "25%      0.000000    0.000000     0.000000          0.0     0.000000   \n",
       "50%      0.000000    2.449032     0.000000          0.0     0.000000   \n",
       "75%      0.000000    4.047310     0.000000          0.0     0.000000   \n",
       "max      0.331808   33.180774     0.666667          0.0     0.666667   \n",
       "\n",
       "       rougeLsum_best  meteor_best   bleu_last  sbleu_last  rouge1_last  \\\n",
       "count      242.000000   242.000000  242.000000  242.000000   242.000000   \n",
       "mean         0.004821     0.080099    0.048083    7.797526     0.013423   \n",
       "std          0.053462     0.100720    0.167598   16.228023     0.093211   \n",
       "min          0.000000     0.000000    0.000000    0.000000     0.000000   \n",
       "25%          0.000000     0.000000    0.000000    1.236216     0.000000   \n",
       "50%          0.000000     0.049020    0.000000    3.089055     0.000000   \n",
       "75%          0.000000     0.111111    0.000000    5.714697     0.000000   \n",
       "max          0.666667     0.531915    1.000000  100.000000     1.000000   \n",
       "\n",
       "       rouge2_last  rougeL_last  rougeLsum_last  meteor_last  \n",
       "count   242.000000   242.000000      242.000000   242.000000  \n",
       "mean      0.001377     0.013423        0.013423     0.148944  \n",
       "std       0.021427     0.093211        0.093211     0.209340  \n",
       "min       0.000000     0.000000        0.000000     0.000000  \n",
       "25%       0.000000     0.000000        0.000000     0.030675  \n",
       "50%       0.000000     0.000000        0.000000     0.072464  \n",
       "75%       0.000000     0.000000        0.000000     0.175198  \n",
       "max       0.333333     1.000000        1.000000     0.999852  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3441daf-001f-40d2-b62c-bf1e9f3e721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_excel(\"T5Metrics.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a2e849b-9d9c-4e4d-aabe-2a17860eb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4375, 219, 242)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_dataset_train), len(title_dataset_val), len(title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93359caf-f0cc-433c-9a9a-ff1bfeef5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_train = title_dataset_train[\"article_ru\"]\n",
    "articles_test = title_dataset_test[\"article_ru\"]\n",
    "articles_val = title_dataset_val[\"article_ru\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "839adad6-4cd2-4f57-a9e5-e9ac84a4ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_test):\n",
    "    if item in articles_train:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b291a1de-6820-4a1e-8f05-201cd2ba0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_test):\n",
    "    if item in articles_val:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a3fcd22-4ba3-4462-a0c3-dd5b8ca1a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_val):\n",
    "    if item in articles_train:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a53c7-8bdd-42ea-8bc5-3b88e95326c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
