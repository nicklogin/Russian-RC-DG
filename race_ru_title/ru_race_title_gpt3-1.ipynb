{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563c7557-9a7e-46a1-8af2-eb7c8cba0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "from typing import Union, Any\n",
    "\n",
    "import pandas as pd\n",
    "import torch as tt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, EvalPrediction\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ba46d5-9b4d-4bba-a0a8-3ebc93bd8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc23b93-7ac2-4c41-88ef-b3f37eb4cd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638f64a3-5783-41af-920a-e1ff93f56fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"title_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    title_dataset = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747a7bf7-adc5-4111-8733-3685a398b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dataset_train, title_dataset_val, title_dataset_test = title_dataset[\"train\"], title_dataset[\"val\"], title_dataset[\"test\"]\n",
    "title_dataset_train = Dataset.from_list(title_dataset_train)\n",
    "title_dataset_val = Dataset.from_list(title_dataset_val)\n",
    "title_dataset_test = Dataset.from_list(title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f1ac0c-43c2-4457-9d74-9cee8dff94a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4375, 219, 242)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_dataset_train), len(title_dataset_val), len(title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4236bd9-e915-468c-9d99-cf3fa808e6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(item[\"answer\"] for item in title_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12531e3b-e9e5-450a-a724-65238d0e4bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(item[\"answer\"] for item in title_dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25b6383-267f-4afa-abae-4b9eb57704f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(item[\"answer\"] for item in title_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78576440-c7d8-4fac-bb2b-20f1d95d1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "  #print(right_answer)\n",
    "  outp = example['article_ru'] + \"\\n\" + \"ВОПРОС: Какое название лучше всего подойдёт для этого текста? \"\n",
    "  outp += f\"ПРАВИЛЬНЫЙ ОТВЕТ: {right_answer}\"\n",
    "  outp += \"\\nНЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\"\n",
    "\n",
    "  inp_gen = outp\n",
    "  distractors = ''\n",
    "\n",
    "  for option in example[\"options_ru\"]:\n",
    "      if option != right_answer:\n",
    "          #print(option)\n",
    "          outp += f\"\\n  {option}\"\n",
    "          distractors += f\"\\n  {option}\"\n",
    "  #print(outp)\n",
    "  #raise Exception\n",
    "  return {\"inp\": outp, \"distractors\": distractors, \"inp_gen\": inp_gen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5024e5-a2d2-4fc3-8fe0-5dccc617559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21fd3b05a9d469fb620eed6d957a8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d912b77886714812b1779f75fbfb6b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83e6787018a4b93b8f68fc59bd87a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_dataset_train = title_dataset_train.map(to_new_format)\n",
    "title_dataset_val = title_dataset_val.map(to_new_format)\n",
    "title_dataset_test = title_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a35125-d171-40dd-a079-3af6f4fd4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"inp\"]\n",
    "    )\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    model_inputs[\"distractor_tokens\"] = tokenizer(\n",
    "        examples[\"distractors\"]\n",
    "    )[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884bee55-5d77-4b55-b3c7-a3ef694b3306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee085fcdefc4f14b14ce9c00218da5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cf983a2e0c4fdb8e625e3dcdeaafe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d50bca3df646ffa31ee49425c0c510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_dataset_train = title_dataset_train.map(preprocess_function, batched=True)\n",
    "title_dataset_val = title_dataset_val.map(preprocess_function, batched=True)\n",
    "title_dataset_test = title_dataset_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ebd699-b12f-4cf6-9872-89f2f84bc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outp_lengths = [len(item) for item in title_dataset_train[\"distractor_tokens\"]]\n",
    "outp_lengths = pd.Series(outp_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98579053-24fa-4e9f-8d65-7ef768d22b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OUTP_LEN = outp_lengths.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d99b2fb-8f7e-4742-8a3c-438d60151f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_OUTP_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b37d04-da12-4829-9ad3-581814327bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_last_break(input_: list[str]) -> list[str]:\n",
    "    output = [s[:s.rfind('\\n')] for s in input_]\n",
    "    return output\n",
    "\n",
    "def parse_options(input_: list[str]) -> list[str]:\n",
    "    output = [s.strip() for s in input_]\n",
    "    output = [set(option.strip() for option in s.split('\\n')) for s in output]\n",
    "    output = [sorted(list(s))[:3] for s in output]\n",
    "    output = ['\\n'.join(s) for s in output]\n",
    "    return output\n",
    "\n",
    "def get_metric_inputs(\n",
    "    input_batch: list[str], label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    FACTOR = 1.1\n",
    "\n",
    "    input_batch_ = tokenizer(input_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    input_length = input_batch_.shape[-1]\n",
    "    output_length = label_batch_.shape[-1]\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=input_length + MAX_OUTP_LEN)\n",
    "        output_batch = output_batch[:,input_length:]\n",
    "\n",
    "    output = tokenizer.batch_decode(output_batch)\n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    del label_batch_\n",
    "\n",
    "    output = cut_last_break(output)\n",
    "    output = parse_options(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metric_values(output: list[str], label_batch: list[str]) -> dict[str, Any]:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06a4522-2dae-43f0-b00c-89cf877da890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict[str, Any]:\n",
    "    # print(\"Entered compute_metrics function\")\n",
    "    # metrics = []\n",
    "    # outputs, distractorss = [], []\n",
    "\n",
    "    # for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    #     slice = title_dataset_val[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "    \n",
    "    #     if slice[\"inp\"]:\n",
    "    #         distractors = slice[\"distractors\"]\n",
    "    #         output = get_metric_inputs(slice[\"inp\"], distractors, model, tokenizer)\n",
    "    #         distractors = parse_options(distractors)\n",
    "    #         outputs += output\n",
    "    #         distractorss += distractors\n",
    "\n",
    "    # print(len(outputs), len(distractorss))\n",
    "\n",
    "    # metrics = compute_metric_values(outputs, distractorss)\n",
    "\n",
    "    # return {\n",
    "    #     \"bleu\": metrics[\"bleu\"][\"bleu\"],\n",
    "    #     \"sbleu\": metrics[\"sbleu\"][\"score\"],\n",
    "    #     \"rouge1\": metrics[\"rouge\"][\"rouge1\"],\n",
    "    #     \"rouge2\": metrics[\"rouge\"][\"rouge2\"],\n",
    "    #     \"rougeL\": metrics[\"rouge\"][\"rougeL\"],\n",
    "    #     \"rougeLsum\": metrics[\"rouge\"][\"rougeLsum\"],\n",
    "    #     \"meteor\": metrics[\"meteor\"][\"meteor\"]\n",
    "    # }\n",
    "    return {\"heh\":1,\"hah\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83ced7f4-b9ce-42fe-a8de-9b906431bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EPOCHS=20\n",
    "BATCH_SIZE=1\n",
    "#STEPS=1000\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./RuGPT3-RuRACE-1\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,   \n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    save_total_limit=3,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    prediction_loss_only=True,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"./rugpt3-rurace-1-title-logs\",\n",
    "    fp16=True, eval_accumulation_steps=1\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=title_dataset_train,\n",
    "    eval_dataset=title_dataset_val,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e061d44-2e43-4053-acdd-9259bc5ec036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.277505397796631,\n",
       " 'eval_runtime': 4.9842,\n",
       " 'eval_samples_per_second': 43.939,\n",
       " 'eval_steps_per_second': 43.939}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd0825b-a8fa-4afa-90d1-162a98848d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_metrics(eval_preds: transformers.trainer_utils.EvalPrediction) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dbf6f37-f7e8-4c3d-a559-49bc49852a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_metrics(eval_preds: transformers.trainer_utils.EvalPrediction) -> dict[str, typing.Any]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e93d2b-e609-4ad6-8a42-1a70ba7e2839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
