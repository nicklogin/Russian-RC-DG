{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec9ef64-729a-4643-a6c9-950a6857b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import evaluate\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch as tt\n",
    "\n",
    "from ast import literal_eval\n",
    "from datasets import load_dataset, Dataset\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from typing import Any, Dict\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb33029-90c6-4a3d-beed-600c287de710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = model.to(tt.device(\"cuda:0\"))\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968c7ced-4eb9-48ee-b3bb-ab1ef35eec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ege = pd.read_excel(\"../race-ru-tf/EgeEvalDataset.xlsx\", index_col=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d234938-728f-4505-9404-71e4d767b1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading_text</th>\n",
       "      <th>question</th>\n",
       "      <th>right_answer</th>\n",
       "      <th>distractors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На задворках нашего села стояло на сваях длин...</td>\n",
       "      <td>Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?</td>\n",
       "      <td>Полонез вызвал у автора желание заплакать и с...</td>\n",
       "      <td>[' Рассказчик был сиротой.', ' В детстве эта м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мы ехали берегом Лены на юг, а зима догоняла ...</td>\n",
       "      <td>Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?</td>\n",
       "      <td>Подобравшись ближе к берегу, козы бросились к...</td>\n",
       "      <td>[' Собеседник рассказчика, Сокольский, сомнева...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Воспалённое состояние Поли, а главное, её сби...</td>\n",
       "      <td>Какое высказывание СООТВЕТСТВУЕТ тексту?</td>\n",
       "      <td>Автор письма хранит подарок девочки.</td>\n",
       "      <td>[' Родион встретил девочку перед наступлением....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Все мы любили «классного», хотя нельзя сказат...</td>\n",
       "      <td>Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?</td>\n",
       "      <td>Ребята сразу невзлюбили своего классного руко...</td>\n",
       "      <td>[' Белый билет не давал учителю возможности уй...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В суровые военные годы во время бомбёжки моя ...</td>\n",
       "      <td>Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?</td>\n",
       "      <td>Бабушка рассказчицы долгое время работала в т...</td>\n",
       "      <td>[' Убежище, в котором укрывалась рассказчица, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reading_text  \\\n",
       "index                                                      \n",
       "0       На задворках нашего села стояло на сваях длин...   \n",
       "1       Мы ехали берегом Лены на юг, а зима догоняла ...   \n",
       "2       Воспалённое состояние Поли, а главное, её сби...   \n",
       "3       Все мы любили «классного», хотя нельзя сказат...   \n",
       "4       В суровые военные годы во время бомбёжки моя ...   \n",
       "\n",
       "                                          question  \\\n",
       "index                                                \n",
       "0      Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?   \n",
       "1      Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?   \n",
       "2         Какое высказывание СООТВЕТСТВУЕТ тексту?   \n",
       "3      Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?   \n",
       "4      Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?   \n",
       "\n",
       "                                            right_answer  \\\n",
       "index                                                      \n",
       "0       Полонез вызвал у автора желание заплакать и с...   \n",
       "1       Подобравшись ближе к берегу, козы бросились к...   \n",
       "2                   Автор письма хранит подарок девочки.   \n",
       "3       Ребята сразу невзлюбили своего классного руко...   \n",
       "4       Бабушка рассказчицы долгое время работала в т...   \n",
       "\n",
       "                                             distractors  \n",
       "index                                                     \n",
       "0      [' Рассказчик был сиротой.', ' В детстве эта м...  \n",
       "1      [' Собеседник рассказчика, Сокольский, сомнева...  \n",
       "2      [' Родион встретил девочку перед наступлением....  \n",
       "3      [' Белый билет не давал учителю возможности уй...  \n",
       "4      [' Убежище, в котором укрывалась рассказчица, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ege.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607b649a-599e-47eb-93e5-3335823bbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ege[\"distractors\"] = df_ege[\"distractors\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b5b464-0c0a-4390-9c86-b12b8b346075",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c437adde-6d2f-4d5d-9a7e-5d2ea76b8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ege_dataset = Dataset.from_pandas(df_ege)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb873aad-846c-47aa-9e7a-ca1767145ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dg_format(dataset: list[dict[str, Any]]) -> list[dict[str, Any]]:\n",
    "    dataset_processed = []\n",
    "    item_id = 0\n",
    "\n",
    "    for item in dataset:\n",
    "        new_item = {\n",
    "            \"item_id\": item[\"index\"],\n",
    "            \"passage\": item[\"reading_text\"],\n",
    "            \"question\": item[\"question\"],\n",
    "            \"distractors\": ';'.join(item[\"distractors\"]),\n",
    "            \"right_answer\": item[\"right_answer\"]\n",
    "        }\n",
    "        dataset_processed.append(new_item)\n",
    "\n",
    "    return dataset_processed\n",
    "\n",
    "\n",
    "def to_dg_format_final(dataset: list[dict[str, Any]]) -> list[dict[str, Any]]:\n",
    "    new_dataset = []\n",
    "\n",
    "    for item in dataset:\n",
    "        new_item = {\n",
    "            \"item_id\": item[\"item_id\"],\n",
    "            \"inp\": f'{item[\"passage\"]} ВОПРОС: {item[\"question\"]} ПРАВИЛЬНЫЙ ОТВЕТ: {item[\"right_answer\"]} НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: ',\n",
    "            \"outp\": item[\"distractors\"],\n",
    "            \"outp_len\": len(tokenizer(item[\"distractors\"])[\"input_ids\"])\n",
    "        }\n",
    "        new_dataset.append(new_item)\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433325d0-8bf8-46d8-bbc9-16de47f4657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ege_dataset = Dataset.from_list(to_dg_format_final(to_dg_format(ege_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0fb2569-01e2-4a63-b3df-7b6ef3c48da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 69 # 0.99 quantile from MuSeRC train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a056e986-bd45-47c4-8eb0-8e1fc9a51e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_inputs_seq2seq(\n",
    "    input_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    input_batch_ = tokenizer(\n",
    "        input_batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "\n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=MAX_LEN)\n",
    "\n",
    "    output = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in tokenizer.batch_decode(\n",
    "            output_batch)\n",
    "    ]\n",
    "    \n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict\n",
    "\n",
    "def compute_metrics_on_dataset_seq2seq(\n",
    "    dataset: Dataset, model: PreTrainedModel=model,\n",
    "    tokenizer: PreTrainedTokenizer=tokenizer\n",
    ") -> pd.DataFrame:\n",
    "    batch_size = 1\n",
    "\n",
    "    n_steps = (len(dataset) // batch_size) + 1\n",
    "    metrics = []\n",
    "\n",
    "    for i in tqdm_notebook(range(n_steps), total=n_steps):\n",
    "        slice = dataset[i*batch_size:(i+1)*batch_size]\n",
    "        if slice[\"inp\"]:\n",
    "            output = get_metric_inputs_seq2seq(slice[\"inp\"], model, tokenizer)\n",
    "            distractors = [\n",
    "                item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip()\n",
    "                for item in slice[\"outp\"]\n",
    "            ]\n",
    "            if len(distractors[0]) > 0:\n",
    "                metric = compute_metrics(output, distractors)\n",
    "                metrics.append({\n",
    "                    \"item_id\": slice[\"item_id\"][0],\n",
    "                    \"inp\": slice[\"inp\"][0],\n",
    "                    \"distractors\": distractors[0],\n",
    "                    \"output\": output[0],\n",
    "        \n",
    "                    \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "                    \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "                    \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "                    \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "                    \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "                    \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "                    \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "METRIC_COLS = [\n",
    "    \"bleu\", \"sbleu\", \"rouge1\", \"rouge2\",\n",
    "    \"rougeL\", \"rougeLsum\", \"meteor\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9fdef03-c644-4838-b7b5-e94257c6402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4177/3452039049.py:43: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(n_steps), total=n_steps):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5623b35d0a04f64bbb90de6ba7d7498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_ege = compute_metrics_on_dataset_seq2seq(ege_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d28816d-f715-4ce4-86de-ff9dec67ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ege.to_csv(\"metrics_baseline_ege_t5.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cdb1f2-c1e4-47eb-8ba1-6343f5b1e7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.509525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bleu      sbleu  rouge1  rouge2  rougeL  rougeLsum     meteor\n",
       "count  55.0  55.000000    55.0    55.0    55.0       55.0  55.000000\n",
       "mean    0.0   0.543768     0.0     0.0     0.0        0.0   0.028705\n",
       "std     0.0   0.294495     0.0     0.0     0.0        0.0   0.017407\n",
       "min     0.0   0.000000     0.0     0.0     0.0        0.0   0.000000\n",
       "25%     0.0   0.420501     0.0     0.0     0.0        0.0   0.015038\n",
       "50%     0.0   0.579998     0.0     0.0     0.0        0.0   0.023364\n",
       "75%     0.0   0.720242     0.0     0.0     0.0        0.0   0.040254\n",
       "max     0.0   1.509525     0.0     0.0     0.0        0.0   0.069832"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_ege[METRIC_COLS].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
