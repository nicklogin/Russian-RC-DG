{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bafc561-654b-4e23-a49f-c9fd1a6e43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any, Dict, Union\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a4a8fe-e042-4861-9b22-7f38059b03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"RuT5-RACE-tf-1/checkpoint-65760\").to(tt.device(\"cuda:0\"))\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ddc5d-fb1b-4859-a1b1-5b339acb3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  inp, label = '', ''\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  right_answer = right_answer.replace('\"', \"'\")\n",
    "\n",
    "  qtext_orig = example[\"question\"].lower()\n",
    "  if (\"not true\" in qtext_orig) or (\"false\" in qtext_orig) or (\"n't true\" in qtext_orig) or (\"untrue\" in qtext_orig):\n",
    "      if (\"not false\" in qtext_orig) or (\"n't false\" in qtext_orig):\n",
    "          inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "      else:\n",
    "          inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту? \"\n",
    "  else:\n",
    "      inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "  inp += f'ПРАВИЛЬНЫЙ ОТВЕТ: \"{right_answer}\".'\n",
    "  inp += 'НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: '\n",
    "\n",
    "  options = example[\"options_ru\"]\n",
    "  options = [\n",
    "      option.replace('\"', \"'\") for option in options if option != right_answer\n",
    "  ]\n",
    "  options = [\n",
    "      f'\"{option}\"' for option in options\n",
    "  ]\n",
    "  label = \"; \".join(options)\n",
    "\n",
    "  distractors_len = len(tokenizer(label)[\"input_ids\"])\n",
    "    \n",
    "  return {\"inp\": inp, \"right_answer\": right_answer, \"distractors\": label, \"distractors_len\": distractors_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d6cee-05ee-40a2-9860-f80bc20828e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626bf4e55554514bd8f624be0c59b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c356778de6b74458b14771b87a76b18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc61e1a5e14141e9901f61d4be92b756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"tf_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    tf_dataset = json.load(inp)\n",
    "\n",
    "tf_dataset_train, tf_dataset_val, tf_dataset_test = tf_dataset[\"train\"], tf_dataset[\"val\"], tf_dataset[\"test\"]\n",
    "tf_dataset_train = Dataset.from_list(tf_dataset_train)\n",
    "tf_dataset_val = Dataset.from_list(tf_dataset_val)\n",
    "tf_dataset_test = Dataset.from_list(tf_dataset_test)\n",
    "\n",
    "tf_dataset_train = tf_dataset_train.map(to_new_format)\n",
    "tf_dataset_val = tf_dataset_val.map(to_new_format)\n",
    "tf_dataset_test = tf_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cdb0e2e-852a-4971-86cb-97a4629e19cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3288.000000\n",
       "mean       47.546533\n",
       "std        11.146655\n",
       "min        21.000000\n",
       "25%        40.000000\n",
       "50%        46.000000\n",
       "75%        54.000000\n",
       "max       136.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(tf_dataset_train[\"distractors_len\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de702f29-456c-454e-a17e-c2ce042f3b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = pd.Series(tf_dataset_train[\"distractors_len\"]).quantile(0.99)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31a9d34-3a7d-4935-b715-490af7b63f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(text: str, model: PreTrainedModel) -> str:\n",
    "    input_ = tokenizer([text], return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    )\n",
    "    return tokenizer.batch_decode(output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab0fc91-1bcb-415b-8f68-42f4b83c02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Почему люди скрещивают пальцы, сталкиваясь с трудностями нерелигиозных людей? Почему мы виним чёрного кота, когда видим низкий балл теста?\n",
      "Эти привычки называются волшебным мышлением и можно найти везде в повседневной жизни. Например, человек хочет чего - то плохого для раздражающего коллеги. Или родители молятся о безопасном бою, когда их сын уходит. \n",
      "Психологическая помощь\n",
      "Изучая эти привычки, ученые решили найти причину, по которой люди верят в магические силы. Психологи имеют свой собственный подход к этому вопросу. \n",
      "\"Я думаю, что отчасти это потому, что мы постоянно подвергаемся воздействию наших собственных мыслей, и поэтому, скорее всего, переоценим их связь с внешними событиями. \"Сказала Эмили Пронин, психолог в префиксе = st1 /US.\n",
      "Для людей, которые не уверены в своих способностях или медленных действиях, волшебное мышление может быть большой помощью, объяснил доктор Дэниел Вегнер, профессор психологии Гарварда. Чувство, что их собственные мысли могут контролировать вещи, может помочь людям бороться с депрессией. \n",
      "Предательство, приобретенное в результате эволюции\n",
      "Но у эволюционистов есть свои собственные идеи. \n",
      "Две школы эволюционного мышления придумали причины, анализируя развитие человека. Они являются « адаптационными » и « теоретиками побочных продуктов ». \n",
      "Адаптационисты говорят, что вера в магические силы заставляет людей чувствовать себя лучше, меньше беспокоиться о трудностях, больше фокусироваться на будущем и больше заботиться о себе. У людей с сильной верой (в чем-то) больше шансов выжить в трудной среде или соперничестве. \n",
      "Но в теории побочных продуктов магическое мышление является продуктом наших психологических особенностей. \n",
      "\"Мы автоматически ищем объяснение того, почему что-то происходит,\" объясняет Джастин Барретт, психолог, мозг, таким образом, эволюционировал, чтобы быстро судить о причинно-следственной связи. Так что мы часто связываем два события, основываясь не более чем на совпадении. Например, « Я просто думала о том, чтобы найти свою старую школьную подружку, когда она вдруг позвонила мне ».\n",
      "Еще одна психологическая особенность — это теория разума. Мы признаем, что может существовать невидимая сила ума, которая влияет на исход инцидента. \n",
      "Теоретики побочных продуктов утверждают, что из-за этих особенностей мы рождаемся с тенденцией верить в наше волшебное мышление. \n",
      "Но нам нужно ограничить наше волшебное мышление, предупредить психологов. \n",
      "Для большинства людей убеждения - это просто утешительный частный ритуал. Когда на карту поставлено что-то важное, например испытание, представление или отношения, люди не просто совершают свои личные ритуалы. Они должны подготовиться. ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? ПРАВИЛЬНЫЙ ОТВЕТ: \"Доктор Дэниел Вегнер считает, что магическое мышление может помочь.\".НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: \n"
     ]
    }
   ],
   "source": [
    "print(tf_dataset_test[42][\"inp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff58be34-a643-490d-96c4-f2770bbda765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Джастин Барретт, эволюционист, отрицает, что магическое мышление является продуктом адаптации.\"; \"У людей со слабой верой больше шансов выжить в соперничестве.\"; \"Адаптационисты думают, что мы рождаемся с тенденцией верить в наше волшебное мышление.\"\n"
     ]
    }
   ],
   "source": [
    "print(tf_dataset_test[42][\"distractors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f754c2-9ccd-4db8-985d-675aa698a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\"Эволюция привела к теории разума.\"; \"Люди рождаются с тенденцией\n"
     ]
    }
   ],
   "source": [
    "predict_model = model_predict(tf_dataset_test[42][\"inp\"], model)\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e6d37f-d061-44f0-bea1-9fdb351726b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У тебя есть какие-нибудь замечательные планы на предстоящие зимние каникулы? Вот замечательные фильмы, чтобы убить время. ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? ПРАВИЛЬНЫЙ ОТВЕТ: \"Сиротка - это комедия об Эстер, усыновленной доброй семьёй.\".НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: \n"
     ]
    }
   ],
   "source": [
    "print(tf_dataset_test[100][\"inp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2243a7-765e-4eb0-b878-02b99a9aee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"500 дней лета - роман с счастливым концом.\"; \"Мы идем показывать красивые пейзажи во время путешествия молодых пар.\"; \"Древнее предсказание майя произойдет в 2012 году.\"\n"
     ]
    }
   ],
   "source": [
    "print(tf_dataset_test[100][\"distractors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de933df-0f05-4a50-8ad7-c05a6bc11c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\"Сротка - комедия об Эстер.\"; \"Сильмовая комедия об Э\n"
     ]
    }
   ],
   "source": [
    "predict_model = model_predict(tf_dataset_test[100][\"inp\"], model)\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "979b414b-cdeb-4d86-a363-9df4ab25ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>\"Сротка - комедия об Эстер.\"; \"Сильмовая комедия об Э\n"
     ]
    }
   ],
   "source": [
    "predict_model = model_predict(tf_dataset_test[100][\"inp\"], model)\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e0bcd7-c20e-4dd8-9518-b59c0650c72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method generate in module transformers.generation.utils:\n",
      "\n",
      "generate(inputs: Optional[torch.Tensor] = None, generation_config: Optional[transformers.generation.configuration_utils.GenerationConfig] = None, logits_processor: Optional[transformers.generation.logits_process.LogitsProcessorList] = None, stopping_criteria: Optional[transformers.generation.stopping_criteria.StoppingCriteriaList] = None, prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], List[int]]] = None, synced_gpus: Optional[bool] = None, assistant_model: Optional[ForwardRef('PreTrainedModel')] = None, streamer: Optional[ForwardRef('BaseStreamer')] = None, negative_prompt_ids: Optional[torch.Tensor] = None, negative_prompt_attention_mask: Optional[torch.Tensor] = None, **kwargs) -> Union[transformers.generation.utils.GenerateDecoderOnlyOutput, transformers.generation.utils.GenerateEncoderDecoderOutput, transformers.generation.utils.GenerateBeamDecoderOnlyOutput, transformers.generation.utils.GenerateBeamEncoderDecoderOutput, torch.LongTensor] method of transformers.models.t5.modeling_t5.T5ForConditionalGeneration instance\n",
      "    Generates sequences of token ids for models with a language modeling head.\n",
      "    \n",
      "    <Tip warning={true}>\n",
      "    \n",
      "    Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the\n",
      "    model's default generation configuration. You can override any `generation_config` by passing the corresponding\n",
      "    parameters to generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`.\n",
      "    \n",
      "    For an overview of generation strategies and code examples, check out the [following\n",
      "    guide](../generation_strategies).\n",
      "    \n",
      "    </Tip>\n",
      "    \n",
      "    Parameters:\n",
      "        inputs (`torch.Tensor` of varying shape depending on the modality, *optional*):\n",
      "            The sequence used as a prompt for the generation or as model inputs to the encoder. If `None` the\n",
      "            method initializes it with `bos_token_id` and a batch size of 1. For decoder-only models `inputs`\n",
      "            should be in the format of `input_ids`. For encoder-decoder models *inputs* can represent any of\n",
      "            `input_ids`, `input_values`, `input_features`, or `pixel_values`.\n",
      "        generation_config (`~generation.GenerationConfig`, *optional*):\n",
      "            The generation configuration to be used as base parametrization for the generation call. `**kwargs`\n",
      "            passed to generate matching the attributes of `generation_config` will override them. If\n",
      "            `generation_config` is not provided, the default will be used, which has the following loading\n",
      "            priority: 1) from the `generation_config.json` model file, if it exists; 2) from the model\n",
      "            configuration. Please note that unspecified parameters will inherit [`~generation.GenerationConfig`]'s\n",
      "            default values, whose documentation should be checked to parameterize generation.\n",
      "        logits_processor (`LogitsProcessorList`, *optional*):\n",
      "            Custom logits processors that complement the default logits processors built from arguments and\n",
      "            generation config. If a logit processor is passed that is already created with the arguments or a\n",
      "            generation config an error is thrown. This feature is intended for advanced users.\n",
      "        stopping_criteria (`StoppingCriteriaList`, *optional*):\n",
      "            Custom stopping criteria that complements the default stopping criteria built from arguments and a\n",
      "            generation config. If a stopping criteria is passed that is already created with the arguments or a\n",
      "            generation config an error is thrown. If your stopping criteria depends on the `scores` input, make\n",
      "            sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`. This feature is\n",
      "            intended for advanced users.\n",
      "        prefix_allowed_tokens_fn (`Callable[[int, torch.Tensor], List[int]]`, *optional*):\n",
      "            If provided, this function constraints the beam search to allowed tokens only at each step. If not\n",
      "            provided no constraint is applied. This function takes 2 arguments: the batch ID `batch_id` and\n",
      "            `input_ids`. It has to return a list with the allowed tokens for the next generation step conditioned\n",
      "            on the batch ID `batch_id` and the previously generated tokens `inputs_ids`. This argument is useful\n",
      "            for constrained generation conditioned on the prefix, as described in [Autoregressive Entity\n",
      "            Retrieval](https://arxiv.org/abs/2010.00904).\n",
      "        synced_gpus (`bool`, *optional*):\n",
      "            Whether to continue running the while loop until max_length. Unless overridden this flag will be set to\n",
      "            `True` under DeepSpeed ZeRO Stage 3 multiple GPUs environment to avoid hanging if one GPU finished\n",
      "            generating before other GPUs. Otherwise it'll be set to `False`.\n",
      "        assistant_model (`PreTrainedModel`, *optional*):\n",
      "            An assistant model that can be used to accelerate generation. The assistant model must have the exact\n",
      "            same tokenizer. The acceleration is achieved when forecasting candidate tokens with the assistent model\n",
      "            is much faster than running generation with the model you're calling generate from. As such, the\n",
      "            assistant model should be much smaller.\n",
      "        streamer (`BaseStreamer`, *optional*):\n",
      "            Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
      "            through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
      "        negative_prompt_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "            The negative prompt needed for some processors such as CFG. The batch size must match the input batch\n",
      "            size. This is an experimental feature, subject to breaking API changes in future versions.\n",
      "        negative_prompt_attention_mask (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
      "            Attention_mask for `negative_prompt_ids`.\n",
      "        kwargs (`Dict[str, Any]`, *optional*):\n",
      "            Ad hoc parametrization of `generation_config` and/or additional model-specific kwargs that will be\n",
      "            forwarded to the `forward` function of the model. If the model is an encoder-decoder model, encoder\n",
      "            specific kwargs should not be prefixed and decoder specific kwargs should be prefixed with *decoder_*.\n",
      "    \n",
      "    Return:\n",
      "        [`~utils.ModelOutput`] or `torch.LongTensor`: A [`~utils.ModelOutput`] (if `return_dict_in_generate=True`\n",
      "        or when `config.return_dict_in_generate=True`) or a `torch.LongTensor`.\n",
      "    \n",
      "            If the model is *not* an encoder-decoder model (`model.config.is_encoder_decoder=False`), the possible\n",
      "            [`~utils.ModelOutput`] types are:\n",
      "    \n",
      "                - [`~generation.GenerateDecoderOnlyOutput`],\n",
      "                - [`~generation.GenerateBeamDecoderOnlyOutput`]\n",
      "    \n",
      "            If the model is an encoder-decoder model (`model.config.is_encoder_decoder=True`), the possible\n",
      "            [`~utils.ModelOutput`] types are:\n",
      "    \n",
      "                - [`~generation.GenerateEncoderDecoderOutput`],\n",
      "                - [`~generation.GenerateBeamEncoderDecoderOutput`]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d178e98e-e2ea-4328-977f-636dedb14793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_inputs_seq2seq(\n",
    "    input_batch: list[str], #label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "    input_batch_ = tokenizer(input_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    # label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    # output_length = label_batch_.shape[-1]\n",
    "\n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=MAX_LEN)\n",
    "\n",
    "    output = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in tokenizer.batch_decode(output_batch) # \n",
    "    ]\n",
    "    \n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    # del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae179de2-929f-4df7-adf6-d17318117596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tf_dataset_test[\"inp\"][:16]\n",
    "right_answers = tf_dataset_test[\"right_answer\"][:16]\n",
    "labels = [item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip() for item in tf_dataset_test[\"distractors\"][:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d727f17-ee18-4171-b071-aa76bc18c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = get_metric_inputs_seq2seq(model_inputs, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd7c8153-42be-4533-ba00-6fab71357fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Самые великие земледелцы пустыни - это люди.\"; \"Пустыни быстро растут.\"; \"Размеры пустыни постоянно меняются.\"',\n",
       " '\"Нельсон Мандела не был его оригинальным именем.\"; \"Нельсон Мандела был назван своим учителем.\"; \"Нельсон Мандела основал свою собственную юридическую фирму до того, как получил степень юриста.\"',\n",
       " '\"Детям нехорошо веселиться летом.\"; \"Детям будет скучно читать программы\"; \"Учителям не нужно помогать детям анализировать уроки.\"',\n",
       " '\"Фестиваль Гластонбери работает на прибыльной основе.\"; \"Джеймс Браун и Джосс Стоун родились в бедных семьях.\"; \"В 1970 году на фестивале Гластонбери можно бесплатно пообедать на ферме.\"',\n",
       " '\"Университет находится в центре города.\"; \"Студенты могут жить на улице.\"; \"Университет не заинтересован в удовлетворении растущих потребностей общества.\"',\n",
       " '\"Все жертвы получили легкие ранения в результате аварии.\"; \"Спасатели были доставлены в больницу для посещения жертв.\"; \"Раненые вскоре оправятся от полученных ранений.\"',\n",
       " '\"Тигр Вудс был смешанным черным, китайским и коренным американцем.\"; \"Тигр Вудс не был первым азиатским американцем, выигравшим Турнир.\"; \"Достичь Тайгера Вудса было потрясающе, потому что он был самым молодым игроком в гольф.\"',\n",
       " '\"Ты должен следовать рутине даже по выходным.\"; \"Время для упражнений имеет важное значение.\"; \"Не вздремни долго, даже если ты очень хочешь спать.\"',\n",
       " '\"Потеря памяти неизбежна.\"; \"Светильность неразумна.\"; \"Мышечные мышцы не нуждаются в упражнениях.\"',\n",
       " '\"Клиенты в Америке, как и другие, используют вспышки, когда едят.\"; \"Американское правительство обсуждает проблему пищевойстаграмации.\"; \"Люди в Китае пытаются придумать идею для решения этой проблемы.\"',\n",
       " '\"Иногда правительство лжет, потому что оно должно отвечать общественным интересам.\"; \"Доктора считают, что если они лгут, то больные серьёзно больных выздоровеют быстрее.\"; \"Многие пациенты не хотят знать правду, особенно о серьезных заболеваниях.\"',\n",
       " '\"Крокодил напал на него, когда мальчик и его мать плавали.\"; \"Крокодил укусил руки мальчика, когда он достиг его.\"; \"За каждым шрамом всегда есть интересная история.\"',\n",
       " '\"Для сокращения люди ничего не могут с этим поделать.\"; \"Если кто-то ранен, он станет короче.\"; \"У женщин меньше и легче костей, чем у мужчин.\"',\n",
       " '\"Однажды компьютер полностью заменит людей.\"; \"В наше время компьютер является единственным самым важным изобретением.\"; \"В будущем мы можем использовать компьютер для всего.\"',\n",
       " '\"Вы можете увидеть в прямом эфире Peking Opera, наслаждаясь китайским традиционным чаем.\"; \"Тебе не нужно беспокоиться о языковой проблеме, чтобы посетить Таичи, если ты англичанин.\"; \"Китайский класс рисования чернил и воды, вероятно, открыт для обучения за пределами Китая.\"',\n",
       " '\"Американцы всегда легко получали доступ к Интернету.\"; \"Мировой телевизор к 2013 году составит 150 миллионов.\"; \"В 2005 году 45% семей в развивающихся странах имели телевизор.\"']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04d11300-92a9-4c39-b824-f206a0ba0b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"В пустыне нет живых существ.\"; \"Люди могут делать пустыни.\"; \"В Иране многие песчаные районы находятся в пределах нефтяной стены.\"',\n",
       " '\"Нельсон Мандела был знаменитой фигурой международной славы.\"; \"Нельсон Мандела любил бокс, потому что он был боксером.\"; \"Нельсон Мандела изучал право в течение 50 лет.\"',\n",
       " '\"Летние программы могут помочь детям улучшить навыки математики.\"; \"Дети должны учиться математике в школе.\"; \"Учащиеся должны учиться математике в школе.\"',\n",
       " '\"Фестиваль Гластонбери проводится в течение трех дней.\"; \"Десятки тысяч молодых людей в Великобритании посещают фестиваль Гластонбери.\"; \"Фестиваль Гластонбери был самым популярным в Великобритании фестивалем.\"',\n",
       " '\"Учебник находится в центре города.\"; \"Учебник Котеборга расположен в центре города.\"; \"Промышленность и торговля в Котеборгском университете являются популярными.\"',\n",
       " '\"Бекки Смит сломала обе ноги и сломала лодыжку.\"; \"Спасатели спасли Мэллори Смит и Меган.\"; \"Все дети в машине погибли в аварии.\"',\n",
       " '\"Тигер Вудс родился в Калифорнии.\"; \"До 1990 года все белые и черные были нездоровы.\"; \"Мишель Ви выразила свою решимость играть на всех турнирах.\"',\n",
       " '\"Не двигайся, если хочешь спать.\"; \"Спать не нужно, если ты не спишь.\"; \"Перекуси, если хочешь спать эффективно.\"',\n",
       " '\"Ученые упражняться в своих умственных способностях.\"; \"Ученые используют лугосити, чтобы упражняться.\"; \"Люди должны упражняться перед экзаменами.\"',\n",
       " '\"В некоторых ресторанах Испании фотографируют свою еду.\"; \"В некоторых ресторанах Испании даже запрещают фотографирование продуктов питания.\"; \"В некоторых ресторанах Испании фотографируют только еду.\"',\n",
       " '\"Врачи всегда могут быть честными.\"; \"Обвинение в медицине помогает предотвратить преступление.\"; \"Врачи должны сказать пациенту правду о его болезни.\"',\n",
       " '\"Мать была очень страстна, чтобы помочь мальчику.\"; \"Крокодил схватил мальчика за ноги.\"; \"Мальчик едва ли пострадал от крокодила.\"',\n",
       " '\"Мы не такие высокие, как мужчины, потому что сжимаемся слишком часто.\"; \"С увеличением костей кости становятся меньше и легче.\"; \"Наши ноги в суставах сжимаются, потому что они меньше сжимаются.\"',\n",
       " '\"Компьютер - это очень дешевый способ поддерживать связь с друзьями и семьей.\"; \"Люди не разрешают своим детям пользоваться Интернетом, потому что он может быть очень полезен.\"; \"Компьютер - это очень хороший способ поддерживать связь с друзьями и семьей.\"',\n",
       " '\"Тебе нужно научиться рисовать с английским рассказом в театре Дяньцяо.\"; \"Плата за чашку чая в театре Дяньцяо Гарден стоит 60 юаней.\"; \"В театре Дяньцяо Хоутонг проводятся акробатические шоу, организованные китайской культурой.\"',\n",
       " '\"Телевидение оказывает позитивное влияние на жизнь людей во всем мире.\"; \"Люди в развивающихся странах не имеют доступа к Интернету.\"; \"Природные ресурсы не имеют ничего общего с насилием, избыточным весом и одиночеством.\"']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecba4301-9983-4035-a63f-bb28146f6964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В пустыне нет живых существ.',\n",
       " 'Нельсон Мандела изучал этот закон без перерыва в течение 50 лет.',\n",
       " 'Летние программы могут помочь детям.',\n",
       " 'Билеты на Фестиваль Гластонбери 2004 года были очень востребованы, несмотря на высокую цену.',\n",
       " 'Культурная жизнь университета очень богата.',\n",
       " 'К счастью, никто не получил слишком серьезных травм во время аварии.',\n",
       " 'Появление Тайгера Вудса на сцене гольфа изменило отношение к этому спорту в США.',\n",
       " 'Ложись спать сразу после горячей ванны.',\n",
       " 'Мозги нужно упражняться.',\n",
       " 'Рестораны в Испании думают о метафоре, чтобы удовлетворить потребности людей.',\n",
       " 'В некоторых случаях правдивая информация помогает пациентам справляться со своей болезнью.',\n",
       " 'Это фермер застрелил крокодила.',\n",
       " 'Мы не такие высокие в конце дня, как в начале.',\n",
       " 'С помощью компьютера, используемого в нашей повседневной жизни, мы можем сделать кое-что попроще, чем раньше.',\n",
       " 'Вы можете наслаждаться акробатическими шоу каждый день в 19 часов на открытом воздухе.',\n",
       " 'Более двух третей семей в мире будут иметь телевизор к 2013 году.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5218caca-aca9-4f9e-af57-fce24626ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': {'bleu': 0.19059422675805282,\n",
       "  'precisions': [0.4160714285714286,\n",
       "   0.2555147058823529,\n",
       "   0.1571969696969697,\n",
       "   0.087890625],\n",
       "  'brevity_penalty': 0.9735698412824109,\n",
       "  'length_ratio': 0.9739130434782609,\n",
       "  'translation_length': 560,\n",
       "  'reference_length': 575},\n",
       " 'sbleu': {'score': 19.059422675805287,\n",
       "  'counts': [233, 139, 83, 45],\n",
       "  'totals': [560, 544, 528, 512],\n",
       "  'precisions': [41.607142857142854,\n",
       "   25.551470588235293,\n",
       "   15.719696969696969,\n",
       "   8.7890625],\n",
       "  'bp': 0.9735698412824109,\n",
       "  'sys_len': 560,\n",
       "  'ref_len': 575},\n",
       " 'rouge': {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0},\n",
       " 'meteor': {'meteor': 0.40420596138295706}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(predict_model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07511fd2-18f9-4ce0-8d0a-d00a1c0a70b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17824/2429130733.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a17940495204d6997f0a25174abd150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(tf_dataset_test) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = tf_dataset_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        output = get_metric_inputs_seq2seq(slice[\"inp\"], model, tokenizer)\n",
    "\n",
    "        distractors = [item.replace('\\n', '').replace('  ',' ').replace('  ',' ').strip() for item in slice[\"distractors\"]]\n",
    "\n",
    "        metric = compute_metrics(output, distractors)\n",
    "\n",
    "        # код далее подходит только для батчей из одиночных примеров (BATCH_SIZE=1):\n",
    "        if \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\" in slice[\"inp\"][0]:\n",
    "            question = \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\"\n",
    "        else:\n",
    "            question = \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "        metrics.append({\n",
    "            \"article\": slice[\"article_ru\"][0],\n",
    "            \"right_answer\": slice[\"right_answer\"][0],\n",
    "            \"question\": question,\n",
    "            \"distractors\": distractors[0],\n",
    "            \"output\": output[0],\n",
    "\n",
    "            \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "            \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "            \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "            \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "            \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "            \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "            \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "\n",
    "            \"article_orig\": slice[\"article\"][0],\n",
    "            \"question_orig\": slice[\"question\"][0],\n",
    "            \"options_orig\": slice[\"options\"][0],\n",
    "            \"right_answer_orig\": slice[\"answer\"][0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "203bc33a-e8d9-47e9-9f10-c06f4993f6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'Пустыня - это прекрасная земля тишины и пространства. Солнце светит, ветер дует, и время и пространство кажется бесконечным. Ничего мягкого. Песок и камни твердые, и во многих растениях даже есть твердые иголки вместо листьев.\\nРазмеры и расположение пустынь в мире постоянно меняются. На протяжении миллионов лет, по мере изменения климата и роста гор, развиваются новые сухие и мокрые районы. Но в последние 100 йен пустыни растут с пугающей скоростью. Отчасти это связано с естественными изменениями, но величайшими создателями являются люди.\\nЛюди могут делать пустыни, но люди также могут препятствовать их росту. Алжир Мавритания размещает аналогичную стену вокруг столицы Нуакшот. Иран помещает тонкий покров нефти на песчаные районы и деревья. Масло держит воду и маленькие деревья на земле, а люди на мотоциклах держат овец и козлов подальше. СССР и Индия строят длинные каналы для доставки воды в пустынные районы.',\n",
       " 'right_answer': 'В пустыне нет живых существ.',\n",
       " 'question': 'ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?',\n",
       " 'distractors': '\"Самые великие земледелцы пустыни - это люди.\"; \"Пустыни быстро растут.\"; \"Размеры пустыни постоянно меняются.\"',\n",
       " 'output': '\"В пустыне нет живых существ.\"; \"Люди могут делать пустыни.\"; \"В Иране многие песчаные районы находятся в пределах нефтяной стены.\"',\n",
       " 'bleu': 0.17878540236558915,\n",
       " 'sbleu': 17.878540236558916,\n",
       " 'rouge1': 0.0,\n",
       " 'rouge2': 0.0,\n",
       " 'rougeL': 0.0,\n",
       " 'rougeLsum': 0.0,\n",
       " 'meteor': 0.48474300962988753,\n",
       " 'article_orig': \"A desert is a beautiful land of silence and space. The sun shines, the wind blows, and time and space seem endless. Nothing is soft. The sand and rocks are hard, and many of the plants even have hard needles instead of leaves.\\nThe size and location  of the world's deserts are always changing. Over millions of years, as climates change and mountains rise, new dry and wet areas develop. But within the last 100 yeas, deserts have been growing at a frightening speed. This is partly because of natural changes, but the greatest makers are humans.\\nHumans can make deserts, but humans can also prevent their growth. Algeria Mauritania is planting a similar wall around   Nouakchott, the capital. Iran puts a thin covering of petroleum  on sandy areas and plants trees. The oil keeps the water and small trees in the land, and men on motorcycles  keep the sheep and goats away. The USSR and India are building long canals to bring water to desert areas.\",\n",
       " 'question_orig': 'Which of the following is NOT true?',\n",
       " 'options_orig': ['The greatest desert makers are humans.',\n",
       "  \"There aren't any living things in the deserts.\",\n",
       "  'Deserts have been growing quickly.',\n",
       "  'The size of the deserts is always changing.'],\n",
       " 'right_answer_orig': 'B'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0aaa914-2a22-49bb-818f-e22c1d469b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3daf446-bcf0-45e5-8221-c0fa0af118c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.205406</td>\n",
       "      <td>20.540558</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.427460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133482</td>\n",
       "      <td>13.348231</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.122983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.077639</td>\n",
       "      <td>7.763937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.136192</td>\n",
       "      <td>13.619166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.160463</td>\n",
       "      <td>16.046299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.214962</td>\n",
       "      <td>21.496191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.914406</td>\n",
       "      <td>91.440619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bleu       sbleu      rouge1  rouge2      rougeL   rougeLsum  \\\n",
       "count  187.000000  187.000000  187.000000   187.0  187.000000  187.000000   \n",
       "mean     0.205406   20.540558    0.017647     0.0    0.017647    0.017647   \n",
       "std      0.133482   13.348231    0.105426     0.0    0.105426    0.105426   \n",
       "min      0.077639    7.763937    0.000000     0.0    0.000000    0.000000   \n",
       "25%      0.136192   13.619166    0.000000     0.0    0.000000    0.000000   \n",
       "50%      0.160463   16.046299    0.000000     0.0    0.000000    0.000000   \n",
       "75%      0.214962   21.496191    0.000000     0.0    0.000000    0.000000   \n",
       "max      0.914406   91.440619    1.000000     0.0    1.000000    1.000000   \n",
       "\n",
       "           meteor  \n",
       "count  187.000000  \n",
       "mean     0.427460  \n",
       "std      0.122983  \n",
       "min      0.224418  \n",
       "25%      0.353397  \n",
       "50%      0.403772  \n",
       "75%      0.467002  \n",
       "max      0.955404  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3441daf-001f-40d2-b62c-bf1e9f3e721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_excel(\"T5Metrics-TF.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a2e849b-9d9c-4e4d-aabe-2a17860eb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3288, 175, 187)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_dataset_train), len(tf_dataset_val), len(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93359caf-f0cc-433c-9a9a-ff1bfeef5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_train = tf_dataset_train[\"article_ru\"]\n",
    "articles_test = tf_dataset_test[\"article_ru\"]\n",
    "articles_val = tf_dataset_val[\"article_ru\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "839adad6-4cd2-4f57-a9e5-e9ac84a4ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_test):\n",
    "    if item in articles_train:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b291a1de-6820-4a1e-8f05-201cd2ba0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_test):\n",
    "    if item in articles_val:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a3fcd22-4ba3-4462-a0c3-dd5b8ca1a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(articles_val):\n",
    "    if item in articles_train:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "505a53c7-8bdd-42ea-8bc5-3b88e95326c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пустыня - это прекрасная земля тишины и пространства. Солнце светит, ветер дует, и время и пространство кажется бесконечным. Ничего мягкого. Песок и камни твердые, и во многих растениях даже есть твердые иголки вместо листьев.\\nРазмеры и расположение пустынь в мире постоянно меняются. На протяжении миллионов лет, по мере изменения климата и роста гор, развиваются новые сухие и мокрые районы. Но в последние 100 йен пустыни растут с пугающей скоростью. Отчасти это связано с естественными изменениями, но величайшими создателями являются люди.\\nЛюди могут делать пустыни, но люди также могут препятствовать их росту. Алжир Мавритания размещает аналогичную стену вокруг столицы Нуакшот. Иран помещает тонкий покров нефти на песчаные районы и деревья. Масло держит воду и маленькие деревья на земле, а люди на мотоциклах держат овец и козлов подальше. СССР и Индия строят длинные каналы для доставки воды в пустынные районы. ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту? ПРАВИЛЬНЫЙ ОТВЕТ: \"В пустыне нет живых существ.\".НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_test[0][\"inp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9db7e-64f1-4899-87e2-cf79dbefa3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
