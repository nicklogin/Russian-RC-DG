{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112ccb3-a799-4ae3-9e50-f33c495cc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "from typing import Union, Any\n",
    "from math import ceil\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94536bd-2527-4313-9b7f-0bd3423d8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"RuGPT3-RuRACE/checkpoint-65760\").to(tt.device(\"cuda:0\"))\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d515c0d8-845c-4bce-920c-f4b1b741d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9bde06ed14452c90e1cf28fc9aed6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240aa5c07b4d47cb9362007b44eedec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea971ef9ca184497bb13a9e03acdef9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"tf_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    tf_dataset = json.load(inp)\n",
    "\n",
    "tf_dataset_train, tf_dataset_val, tf_dataset_test = tf_dataset[\"train\"], tf_dataset[\"val\"], tf_dataset[\"test\"]\n",
    "tf_dataset_train = Dataset.from_list(tf_dataset_train)\n",
    "tf_dataset_val = Dataset.from_list(tf_dataset_val)\n",
    "tf_dataset_test = Dataset.from_list(tf_dataset_test)\n",
    "\n",
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  qtext_orig = example[\"question\"].lower()\n",
    "  outp = \"\"\n",
    "\n",
    "  if (\"not true\" in qtext_orig) or (\"false\" in qtext_orig) or (\"n't true\" in qtext_orig) or (\"untrue\" in qtext_orig):\n",
    "    if (\"not false\" in qtext_orig) or (\"n't false\" in qtext_orig):\n",
    "      outp += example['article_ru'] + \"\\n\" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "    else:\n",
    "      outp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту? \"\n",
    "  else:\n",
    "      outp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "  outp += f\"ПРАВИЛЬНЫЙ ОТВЕТ: {right_answer}\"\n",
    "  outp += \"\\nНЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\"\n",
    "\n",
    "  inp = outp\n",
    "\n",
    "  distractors = ''\n",
    "  for option in example[\"options_ru\"]:\n",
    "      if option != right_answer:\n",
    "          #print(option)\n",
    "          outp += f\"\\n  {option}\"\n",
    "          distractors += f\"\\n  {option}\"\n",
    "\n",
    "  # print(distractors)\n",
    "  distractors_len = len(tokenizer(distractors)[\"input_ids\"])\n",
    "  # print(distractors_len)\n",
    "  #print(outp)\n",
    "  #raise Exception\n",
    "  return {\"inp\": inp, \"distractors_len\": distractors_len, \"outp_expected\": outp, \"distractors\": distractors,\"right_answer\": right_answer}\n",
    "\n",
    "tf_dataset_train = tf_dataset_train.map(to_new_format)\n",
    "tf_dataset_val = tf_dataset_val.map(to_new_format)\n",
    "tf_dataset_test = tf_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944fa264-de12-4e69-be51-2949d78c5974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  Самые великие земледелцы пустыни - это люди.\\n  Пустыни быстро растут.\\n  Размеры пустыни постоянно меняются.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_test[\"distractors\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0dbe9c-037c-487c-a783-7c2b737c96a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3288.000000\n",
       "mean       42.045012\n",
       "std         9.755723\n",
       "min        19.000000\n",
       "25%        35.000000\n",
       "50%        41.000000\n",
       "75%        48.000000\n",
       "max       101.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors_len = pd.Series(tf_dataset_train[\"distractors_len\"])\n",
    "distractors_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c701ee4f-54dd-4572-bb87-07c2737b28ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_OUTPUT_LENGTH = distractors_len.quantile(0.99)\n",
    "MAX_OUTPUT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f69a70-9ec5-43cb-8176-fe78f4cda354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_last_break(input_: list[str]) -> list[str]:\n",
    "    output = [s[:s.rfind('\\n')] for s in input_]\n",
    "    return output\n",
    "\n",
    "def parse_options(input_: list[str]) -> list[str]:\n",
    "    output = [s.strip() for s in input_]\n",
    "    output = [set(option.strip() for option in s.split('\\n')) for s in output]\n",
    "    output = [sorted(list(s))[:3] for s in output]\n",
    "    output = ['\\n'.join(s) for s in output]\n",
    "    return output\n",
    "\n",
    "def get_metric_inputs(\n",
    "    input_batch: list[str], label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "\n",
    "    input_batch_ = tokenizer(input_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    input_length = input_batch_.shape[-1]\n",
    "    output_length = label_batch_.shape[-1]\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=input_length + MAX_OUTPUT_LENGTH)\n",
    "        output_batch = output_batch[:,input_length:]\n",
    "\n",
    "    output = tokenizer.batch_decode(output_batch)\n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    output = cut_last_break(output)\n",
    "    output = parse_options(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict[str, Any]:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930afc0d-3a89-4990-a217-c5ae6e3a765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "input_batch = tf_dataset_test[\"inp\"][:BATCH_SIZE]\n",
    "label_batch = tf_dataset_test[\"distractors\"][:BATCH_SIZE]\n",
    "rans_batch = tf_dataset_test[\"right_answer\"][:BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f4b58e-c71c-4dfa-a20f-4ac462e825e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n  Самые великие земледелцы пустыни - это люди.\\n  Пустыни быстро растут.\\n  Размеры пустыни постоянно меняются.',\n",
       " '\\n  Нельсон Мандела не был его оригинальным именем.\\n  Нельсон Мандела был назван своим учителем.\\n  Нельсон Мандела основал свою собственную юридическую фирму до того, как получил степень юриста.',\n",
       " '\\n  Детям нехорошо веселиться летом.\\n  Детям будет скучно читать программы\\n  Учителям не нужно помогать детям анализировать уроки.',\n",
       " '\\n  Фестиваль Гластонбери работает на прибыльной основе.\\n  Джеймс Браун и Джосс Стоун родились в бедных семьях.\\n  В 1970 году на фестивале Гластонбери можно бесплатно пообедать на ферме.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c02f30-d3b8-4b56-8c2b-0e3b5135f54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Пустыни быстро растут.\\nРазмеры пустыни постоянно меняются.\\nСамые великие земледелцы пустыни - это люди.',\n",
       " 'Нельсон Мандела был назван своим учителем.\\nНельсон Мандела не был его оригинальным именем.\\nНельсон Мандела основал свою собственную юридическую фирму до того, как получил степень юриста.',\n",
       " 'Детям будет скучно читать программы\\nДетям нехорошо веселиться летом.\\nУчителям не нужно помогать детям анализировать уроки.',\n",
       " 'В 1970 году на фестивале Гластонбери можно бесплатно пообедать на ферме.\\nДжеймс Браун и Джосс Стоун родились в бедных семьях.\\nФестиваль Гластонбери работает на прибыльной основе.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_options(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc86b364-9e8b-4964-a7e2-4ee6f0551734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В пустыне нет живых существ.',\n",
       " 'Нельсон Мандела изучал этот закон без перерыва в течение 50 лет.',\n",
       " 'Летние программы могут помочь детям.',\n",
       " 'Билеты на Фестиваль Гластонбери 2004 года были очень востребованы, несмотря на высокую цену.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rans_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6860e902-4c5e-404c-bb7e-1832859f7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = get_metric_inputs(input_batch, label_batch, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60403f30-5e10-4c2f-a341-7309abdd7110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В конце концов, человек был создан.\\nВ последние 100 лет на протяжении миллионов лет менялись большие и мягкие пустыни.\\nЛюди могут видеть деревья на вершине холма.',\n",
       " 'В 1954 году г-н Мандела создал первую черную юридическую компанию.\\nВ течение 50 лет он изучал право только ночью.\\nЕго спасла работа тамбовского адвоката.',\n",
       " 'Дети могут читать в летние каникулы.\\nДетям следует избегать телевидения во время летних каникул.\\nНе следует поощрять родителей читать детям отрывки.',\n",
       " 'В конце 70-х годов фестиваль был закрыт.\\nФестиваль вГластонбери был популярен в течение долгого времени.\\nФестиваль вГластонбери был популярен по-своему.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895e7c12-95a1-4b63-b85b-ecacad00976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20540/3559101089.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a68bc871bfb460cb8bc3e02416a2726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(tf_dataset_test) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = tf_dataset_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        if \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\" in slice[\"inp\"][0]:\n",
    "            question = \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\"\n",
    "        else:\n",
    "            question = \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "        distractors = slice[\"distractors\"]\n",
    "\n",
    "        output = get_metric_inputs(slice[\"inp\"], distractors, model, tokenizer)\n",
    "\n",
    "        distractors = parse_options(distractors)\n",
    "\n",
    "        metric = compute_metrics(output, distractors)\n",
    "\n",
    "        # код далее подходит только для батчей из одиночных примеров (BATCH_SIZE=1):\n",
    "        metrics.append({\n",
    "            \"article\": slice[\"article_ru\"][0],\n",
    "            \"right_answer\": slice[\"right_answer\"][0],\n",
    "            \"question\": question,\n",
    "            \"distractors\": distractors[0],\n",
    "            \"output\": output[0],\n",
    "\n",
    "            \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "            \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "            \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "            \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "            \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "            \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "            \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "\n",
    "            \"article_orig\": slice[\"article\"][0],\n",
    "            \"question_orig\": slice[\"question\"][0],\n",
    "            \"options_orig\": slice[\"options\"][0],\n",
    "            \"right_answer_orig\": slice[\"answer\"][0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2d2ed4-b977-4a1c-a09c-7b89dfae81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e88020-e7cc-498c-99bf-84f7604b1d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.024799</td>\n",
       "      <td>4.993892</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.168441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.094375</td>\n",
       "      <td>8.949587</td>\n",
       "      <td>0.087820</td>\n",
       "      <td>0.046701</td>\n",
       "      <td>0.087820</td>\n",
       "      <td>0.087820</td>\n",
       "      <td>0.122401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.637173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.196244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.143042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.682812</td>\n",
       "      <td>68.281201</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bleu       sbleu      rouge1      rouge2      rougeL   rougeLsum  \\\n",
       "count  187.000000  187.000000  187.000000  187.000000  187.000000  187.000000   \n",
       "mean     0.024799    4.993892    0.012860    0.004813    0.012860    0.012860   \n",
       "std      0.094375    8.949587    0.087820    0.046701    0.087820    0.087820   \n",
       "min      0.000000    0.721067    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.637173    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    2.196244    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    4.143042    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.682812   68.281201    0.666667    0.500000    0.666667    0.666667   \n",
       "\n",
       "           meteor  \n",
       "count  187.000000  \n",
       "mean     0.168441  \n",
       "std      0.122401  \n",
       "min      0.041152  \n",
       "25%      0.092316  \n",
       "50%      0.130548  \n",
       "75%      0.191467  \n",
       "max      0.756045  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b91085e9-8f7e-4b49-a05a-788c4fd7237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_excel(\"RuGPT3Metrics-TF.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172bb3ef-1aa9-48e5-9702-50d80110fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_dataset_text(text: str) -> str:\n",
    "#     find_str = \"НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\\n\"\n",
    "#     split_id = text.find(find_str)\n",
    "#     split_id += len(find_str)\n",
    "#     return text[:split_id], text[split_id:]\n",
    "\n",
    "# def model_predict(text: str, model: PreTrainedModel, max_length: int=1000) -> str:\n",
    "#     input_ = tokenizer([text], return_tensors=\"pt\")\n",
    "#     try:\n",
    "#         output = model.generate(\n",
    "#             input_[\"input_ids\"].to(tt.device(\"cuda:0\")),\n",
    "#             max_length=max_length\n",
    "#         )\n",
    "#         return tokenizer.batch_decode(output)[0]\n",
    "#     except:\n",
    "#         return \"Max length exceeded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c22de3f-d947-4ba4-8394-2f5d46611ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tf_dataset_train), len(tf_dataset_val), len(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b966dcc-984a-4e0f-8414-cd267602627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20520909-4b7e-4585-b26c-199bbc9e699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in tqdm_notebook(tf_dataset_test, total=len(tf_dataset_test)):\n",
    "#     inp, label = preprocess_dataset_text(item[\"inp\"])\n",
    "#     best_model_prediction = model_predict(inp, model_best)\n",
    "#     last_model_prediction = model_predict(inp, model_last)\n",
    "#     df_predictions.append(\n",
    "#         {\n",
    "#             \"input\": inp,\n",
    "#             \"label\": label,\n",
    "#             \"best_model_prediction\": best_model_prediction,\n",
    "#             \"last_model_prediction\": last_model_prediction\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be447c7-77c8-4294-aa5e-1f79e6e49a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_predictions = pd.DataFrame(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea93ce0-29e3-443c-801d-403c98aa1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_predictions.to_csv(\"rugpt3_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84481b34-02af-4a52-a176-b0a5230fd48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
