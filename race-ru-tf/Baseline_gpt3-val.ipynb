{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112ccb3-a799-4ae3-9e50-f33c495cc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "from typing import Union, Any\n",
    "from math import ceil\n",
    "\n",
    "import evaluate\n",
    "import torch as tt\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94536bd-2527-4313-9b7f-0bd3423d8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# models:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\").to(tt.device(\"cuda:0\"))\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d515c0d8-845c-4bce-920c-f4b1b741d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949ddf9c86ff4e828ff1b85b242bf5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4c9613d4c443e4ae769a3c571241a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1575d0fc5d043d8b70ad877a00c71b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"tf_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    tf_dataset = json.load(inp)\n",
    "\n",
    "tf_dataset_train, tf_dataset_val, tf_dataset_test = tf_dataset[\"train\"], tf_dataset[\"val\"], tf_dataset[\"test\"]\n",
    "tf_dataset_train = Dataset.from_list(tf_dataset_train)\n",
    "tf_dataset_val = Dataset.from_list(tf_dataset_val)\n",
    "tf_dataset_test = Dataset.from_list(tf_dataset_test)\n",
    "\n",
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  qtext_orig = example[\"question\"].lower()\n",
    "  outp = \"\"\n",
    "\n",
    "  if (\"not true\" in qtext_orig) or (\"false\" in qtext_orig) or (\"n't true\" in qtext_orig) or (\"untrue\" in qtext_orig):\n",
    "    if (\"not false\" in qtext_orig) or (\"n't false\" in qtext_orig):\n",
    "      outp += example['article_ru'] + \"\\n\" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "    else:\n",
    "      outp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту? \"\n",
    "  else:\n",
    "      outp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "  outp += f\"ПРАВИЛЬНЫЙ ОТВЕТ: {right_answer}\"\n",
    "  outp += \"\\nНЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА:\"\n",
    "\n",
    "  inp = outp\n",
    "\n",
    "  distractors = ''\n",
    "  for option in example[\"options_ru\"]:\n",
    "      if option != right_answer:\n",
    "          #print(option)\n",
    "          outp += f\"\\n  {option}\"\n",
    "          distractors += f\"\\n  {option}\"\n",
    "\n",
    "  # print(distractors)\n",
    "  distractors_len = len(tokenizer(distractors)[\"input_ids\"])\n",
    "  # print(distractors_len)\n",
    "  #print(outp)\n",
    "  #raise Exception\n",
    "  return {\"inp\": inp, \"distractors_len\": distractors_len, \"outp_expected\": outp, \"distractors\": distractors,\"right_answer\": right_answer}\n",
    "\n",
    "tf_dataset_train = tf_dataset_train.map(to_new_format)\n",
    "tf_dataset_val = tf_dataset_val.map(to_new_format)\n",
    "tf_dataset_test = tf_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944fa264-de12-4e69-be51-2949d78c5974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  Самые великие земледелцы пустыни - это люди.\\n  Пустыни быстро растут.\\n  Размеры пустыни постоянно меняются.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_test[\"distractors\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0dbe9c-037c-487c-a783-7c2b737c96a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3288.000000\n",
       "mean       42.045012\n",
       "std         9.755723\n",
       "min        19.000000\n",
       "25%        35.000000\n",
       "50%        41.000000\n",
       "75%        48.000000\n",
       "max       101.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors_len = pd.Series(tf_dataset_train[\"distractors_len\"])\n",
    "distractors_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c701ee4f-54dd-4572-bb87-07c2737b28ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_OUTPUT_LENGTH = distractors_len.quantile(0.99)\n",
    "MAX_OUTPUT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f69a70-9ec5-43cb-8176-fe78f4cda354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_last_break(input_: list[str]) -> list[str]:\n",
    "    output = [s[:s.rfind('\\n')] for s in input_]\n",
    "    return output\n",
    "\n",
    "def parse_options(input_: list[str]) -> list[str]:\n",
    "    output = [s.strip() for s in input_]\n",
    "    output = [set(option.strip() for option in s.split('\\n')) for s in output]\n",
    "    output = [sorted(list(s))[:3] for s in output]\n",
    "    output = ['\\n'.join(s) for s in output]\n",
    "    return output\n",
    "\n",
    "def get_metric_inputs(\n",
    "    input_batch: list[str], label_batch: list[str],\n",
    "    model: PreTrainedModel, tokenizer: PreTrainedTokenizer\n",
    ") -> list[str]:\n",
    "\n",
    "    input_batch_ = tokenizer(input_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(tt.device(\"cuda:0\"))\n",
    "    label_batch_ = tokenizer(label_batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "\n",
    "    input_length = input_batch_.shape[-1]\n",
    "    output_length = label_batch_.shape[-1]\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        output_batch = model.generate(input_batch_, max_length=input_length + MAX_OUTPUT_LENGTH)\n",
    "        output_batch = output_batch[:,input_length:]\n",
    "\n",
    "    output = tokenizer.batch_decode(output_batch)\n",
    "    del input_batch_\n",
    "    del output_batch\n",
    "    del label_batch_\n",
    "    tt.cuda.empty_cache()\n",
    "\n",
    "    output = cut_last_break(output)\n",
    "    output = parse_options(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "def compute_metrics(output: list[str], label_batch: list[str]) -> dict[str, Any]:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930afc0d-3a89-4990-a217-c5ae6e3a765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "input_batch = tf_dataset_test[\"inp\"][:BATCH_SIZE]\n",
    "label_batch = tf_dataset_test[\"distractors\"][:BATCH_SIZE]\n",
    "rans_batch = tf_dataset_test[\"right_answer\"][:BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f4b58e-c71c-4dfa-a20f-4ac462e825e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n  Самые великие земледелцы пустыни - это люди.\\n  Пустыни быстро растут.\\n  Размеры пустыни постоянно меняются.',\n",
       " '\\n  Нельсон Мандела не был его оригинальным именем.\\n  Нельсон Мандела был назван своим учителем.\\n  Нельсон Мандела основал свою собственную юридическую фирму до того, как получил степень юриста.',\n",
       " '\\n  Детям нехорошо веселиться летом.\\n  Детям будет скучно читать программы\\n  Учителям не нужно помогать детям анализировать уроки.',\n",
       " '\\n  Фестиваль Гластонбери работает на прибыльной основе.\\n  Джеймс Браун и Джосс Стоун родились в бедных семьях.\\n  В 1970 году на фестивале Гластонбери можно бесплатно пообедать на ферме.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c02f30-d3b8-4b56-8c2b-0e3b5135f54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Пустыни быстро растут.\\nРазмеры пустыни постоянно меняются.\\nСамые великие земледелцы пустыни - это люди.',\n",
       " 'Нельсон Мандела был назван своим учителем.\\nНельсон Мандела не был его оригинальным именем.\\nНельсон Мандела основал свою собственную юридическую фирму до того, как получил степень юриста.',\n",
       " 'Детям будет скучно читать программы\\nДетям нехорошо веселиться летом.\\nУчителям не нужно помогать детям анализировать уроки.',\n",
       " 'В 1970 году на фестивале Гластонбери можно бесплатно пообедать на ферме.\\nДжеймс Браун и Джосс Стоун родились в бедных семьях.\\nФестиваль Гластонбери работает на прибыльной основе.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_options(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc86b364-9e8b-4964-a7e2-4ee6f0551734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В пустыне нет живых существ.',\n",
       " 'Нельсон Мандела изучал этот закон без перерыва в течение 50 лет.',\n",
       " 'Летние программы могут помочь детям.',\n",
       " 'Билеты на Фестиваль Гластонбери 2004 года были очень востребованы, несмотря на высокую цену.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rans_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6860e902-4c5e-404c-bb7e-1832859f7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = get_metric_inputs(input_batch, label_batch, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60403f30-5e10-4c2f-a341-7309abdd7110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В пустыне нет живых существ.',\n",
       " 'В тексте нет ни слова о том, что он изучал этот закон.\\nНЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: В тексте нет ни слова о том, что он изучал этот закон.',\n",
       " '1. Вы должны быть готовы к тому, что дети будут скучать по школе.\\n2. Вы должны быть готовы к тому, что дети будут скучать по школе.\\n3. Вы должны быть готовы к тому, что дети будут скучать по школе.',\n",
       " 'Билеты на Фестиваль Гластонбери 2004 года были очень дорогими, и многие люди, которые заплатили за них, не смогли бы заплатить за них.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895e7c12-95a1-4b63-b85b-ecacad00976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102544/4257642561.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47772d1c0b948e7abbabd4f55d40c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "N_STEPS = (len(tf_dataset_val) // BATCH_SIZE) + 1\n",
    "\n",
    "metrics_val = []\n",
    "\n",
    "for i in tqdm_notebook(range(N_STEPS), total=N_STEPS):\n",
    "    slice = tf_dataset_val[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    if slice[\"inp\"]:\n",
    "        if \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\" in slice[\"inp\"][0]:\n",
    "            question = \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту?\"\n",
    "        else:\n",
    "            question = \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "        distractors = slice[\"distractors\"]\n",
    "\n",
    "        output = get_metric_inputs(slice[\"inp\"], distractors, model, tokenizer)\n",
    "\n",
    "        distractors = parse_options(distractors)\n",
    "\n",
    "        try:\n",
    "            metric = compute_metrics(output, distractors)\n",
    "            metrics_val.append({\n",
    "                \"article\": slice[\"article_ru\"][0],\n",
    "                \"right_answer\": slice[\"right_answer\"][0],\n",
    "                \"question\": question,\n",
    "                \"distractors\": distractors[0],\n",
    "                \"output\": output[0],\n",
    "    \n",
    "                \"bleu\": metric[\"bleu\"][\"bleu\"],\n",
    "                \"sbleu\": metric[\"sbleu\"][\"score\"],\n",
    "                \"rouge1\": metric[\"rouge\"][\"rouge1\"],\n",
    "                \"rouge2\": metric[\"rouge\"][\"rouge2\"],\n",
    "                \"rougeL\": metric[\"rouge\"][\"rougeL\"],\n",
    "                \"rougeLsum\": metric[\"rouge\"][\"rougeLsum\"],\n",
    "                \"meteor\": metric[\"meteor\"][\"meteor\"],\n",
    "    \n",
    "                \"article_orig\": slice[\"article\"][0],\n",
    "                \"question_orig\": slice[\"question\"][0],\n",
    "                \"options_orig\": slice[\"options\"][0],\n",
    "                \"right_answer_orig\": slice[\"answer\"][0]\n",
    "            })\n",
    "        except ZeroDivisionError:\n",
    "            metrics_val.append({\n",
    "                \"article\": slice[\"article_ru\"][0],\n",
    "                \"right_answer\": slice[\"right_answer\"][0],\n",
    "                \"question\": question,\n",
    "                \"distractors\": distractors[0],\n",
    "                \"output\": output[0],\n",
    "    \n",
    "                \"bleu\": 0,\n",
    "                \"sbleu\": 0,\n",
    "                \"rouge1\": 0,\n",
    "                \"rouge2\": 0,\n",
    "                \"rougeL\": 0,\n",
    "                \"rougeLsum\": 0,\n",
    "                \"meteor\": 0,\n",
    "    \n",
    "                \"article_orig\": slice[\"article\"][0],\n",
    "                \"question_orig\": slice[\"question\"][0],\n",
    "                \"options_orig\": slice[\"options\"][0],\n",
    "                \"right_answer_orig\": slice[\"answer\"][0]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2d2ed4-b977-4a1c-a09c-7b89dfae81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val = pd.DataFrame(metrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19e88020-e7cc-498c-99bf-84f7604b1d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>sbleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002290</td>\n",
       "      <td>1.850458</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015762</td>\n",
       "      <td>1.825498</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.060066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.491224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.964326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.154206</td>\n",
       "      <td>15.420559</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.351562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bleu       sbleu      rouge1  rouge2      rougeL   rougeLsum  \\\n",
       "count  175.000000  175.000000  175.000000   175.0  175.000000  175.000000   \n",
       "mean     0.002290    1.850458    0.017451     0.0    0.017451    0.017451   \n",
       "std      0.015762    1.825498    0.099242     0.0    0.099242    0.099242   \n",
       "min      0.000000    0.000000    0.000000     0.0    0.000000    0.000000   \n",
       "25%      0.000000    0.838847    0.000000     0.0    0.000000    0.000000   \n",
       "50%      0.000000    1.491224    0.000000     0.0    0.000000    0.000000   \n",
       "75%      0.000000    1.964326    0.000000     0.0    0.000000    0.000000   \n",
       "max      0.154206   15.420559    0.666667     0.0    0.666667    0.666667   \n",
       "\n",
       "           meteor  \n",
       "count  175.000000  \n",
       "mean     0.095359  \n",
       "std      0.060066  \n",
       "min      0.000000  \n",
       "25%      0.052402  \n",
       "50%      0.080386  \n",
       "75%      0.124826  \n",
       "max      0.351562  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b91085e9-8f7e-4b49-a05a-788c4fd7237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val.to_excel(\"RuGPT3Metrics-TF-Baseline-val.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e60b7-5863-411b-8d58-9796308d1b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
