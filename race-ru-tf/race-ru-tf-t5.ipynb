{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a112ccb3-a799-4ae3-9e50-f33c495cc737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fd261e-939f-454f-ac0b-bb6b21e2a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, EvalPrediction\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from typing import Any, Dict, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef47b2f3-333d-4202-b216-7a511e7ddb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/lib/python3/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"ai-forever/ruT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca8ed4b-19f8-4b40-96e8-9ab505a89271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# metrics:\n",
    "bleu4 = evaluate.load(\"bleu\")\n",
    "sbleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e34b844-6f36-493d-8098-f26c2c14c39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebcd10c-f28d-4205-8b7b-61144db35542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e97ed8-a8ff-47a7-b6bb-9e161bd8cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tf_dataset_pretty_filtered.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    tf_dataset = json.load(inp)\n",
    "\n",
    "tf_dataset_train, tf_dataset_val, tf_dataset_test = tf_dataset[\"train\"], tf_dataset[\"val\"], tf_dataset[\"test\"]\n",
    "tf_dataset_train = Dataset.from_list(tf_dataset_train)\n",
    "tf_dataset_val = Dataset.from_list(tf_dataset_val)\n",
    "tf_dataset_test = Dataset.from_list(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bdd053-7726-4d01-975d-e5d93af1a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3288, 175, 187)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_dataset_train), len(tf_dataset_val), len(tf_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b104ec-25b8-4830-a6cb-a2ca52845259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': 'high15596.txt',\n",
       " 'article': 'YUZHOU, HENAN -An accident in a central China coal mine killed 21 miners Saturday and left another 16 trapped underground , the government said.\\nThe death\\nrose to 26 Sunday morning as rescuers were battling to reach the 11 miners who were still trapped underground, rescue headquarters said.\\nRescuers were battling to reach the 11 miners still trapped underground, but chances for them to survive were very slim, said Du Bo, deputy chief of the rescue headquarters.\\n\"Based upon past experience, the remaining 11 miners could be buried in coal dust, so the survival chances are frail,\" Du said.\\nMore than 2,500 tons of coal dust smothered  the pit after the gas leak , which hampered  the rescue, said Du.\\nThe gas outburst happened at 6:03 a.m. Saturday when 276 miners were working underground in the mine in Yuzhou City. A total of 239 workers escaped but 21 were found dead and 16 trapped.\\nAn initial  investigation showed that 173,500 cubic meters of gas leaked out in the accident. Liu Wenbin, a deputy chief engineer of the company that owns the mine, was in the pit  when the accident happened. He organized the escape.\\n\"At around 6 a.m., I felt there was something wrong with the airflow in the shaft, and one of the team captains told me he also felt it and had already reported the problem,\" said Liu\\nThe mine is owned by Pingyu Coal & Electric Co. Ltd., a company jointly established by four investors, including Zhong Ping Energy Chemical Group and China Power Investment Corp.',\n",
       " 'answer': 'C',\n",
       " 'question': 'According to the writer, which of the following is not true?',\n",
       " 'options': ['The mine was owned by more than one company',\n",
       "  'There was at least one more similar accident happening in Central China before',\n",
       "  'Before the accident happened there was no sign of something wrong',\n",
       "  'When the accident happened one of the mine owners was in the pit'],\n",
       " 'article_ru': 'YUZHOU, HENAN - Несчастный случай на центрально-китайской угольной шахте убил 21 шахтера в субботу и оставил еще 16 запертых под землей, - говорит правительство.\\nСмерть\\nПо словам спасательной штаб-квартиры, они поднялись до 26 воскресных утра, когда спасатели боролись за то, чтобы добраться до 11 шахтеров, которые все еще были в ловушке под землей.\\nСпасатели боролись за то, чтобы добраться до 11 шахтеров, все еще запертых в подполье, но шансы выжить были очень малы, сказал Дю Бо, заместитель начальника спасательного штаба.\\n«С учетом прошлого опыта оставшиеся 11 шахтеров могут быть погребены в угольной пыли, поэтому шансы на выживание слабы», — сказал Ду.\\nБолее 2500 тонн угольной пыли задушили яму после утечки газа, которая затруднила спасательный процесс, сказал Ду.\\nВырыв газа произошел в 6:03 утра в субботу, когда 276 шахтеров работали под землей на шахте в городе Ючжоу. В общей сложности 239 рабочих сбежали, однако 21 человек был найден мертвым и 16 человек оказались в ловушке.\\nПервоначальное расследование показало, что 173 500 кубических метров газа вытекло в результате аварии. Лю Венбин, заместитель главного инженера компании, которая владеет шахтой, был в яме, когда произошел несчастный случай. Он организовал побег.\\n\"Через 6 часов утра я почувствовал, что что-то не так с потоком воздуха в шахте, и один из капитанов команды сказал мне, что он также почувствовал это и уже сообщил о проблеме\", сказал Лю\\nЭта шахта принадлежит компании \"Pingyu Coal & Electric Co. Ltd.\", совместно созданной четырьмя инвесторами, включая \"Zhong Ping Energy Chemical Group\" и China Power Investment Corp.',\n",
       " 'question_ru': 'По словам автора, какая из следующих частей не соответствует действительности?',\n",
       " 'options_ru': ['',\n",
       "  'Эта шахта принадлежала более чем одной компании',\n",
       "  'По крайней мере, еще одна аналогичная авария произошла в Центральном Китае до этого.',\n",
       "  'До того, как произошел несчастный случай, не было никаких признаков того, что что-то не так.',\n",
       "  'Когда произошёл несчастный случай, один из владельцев шахт был в яме.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d53025-7b71-4f6f-a950-3158a5a61876",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_id_dict = {\n",
    "    'A': 0, 'B': 1, 'C': 2, 'D': 3\n",
    "}\n",
    "\n",
    "def to_new_format(example: dict[str, Union[str, list[str]]]) -> str:\n",
    "  inp, label = '', ''\n",
    "  example[\"options_ru\"] = [option for option in example[\"options_ru\"] if option]\n",
    "  right_answer = example['options_ru'][option_id_dict[example['answer']]]\n",
    "\n",
    "  right_answer = right_answer.replace('\"', \"'\")\n",
    "\n",
    "  qtext_orig = example[\"question\"].lower()\n",
    "  if (\"not true\" in qtext_orig) or (\"false\" in qtext_orig) or (\"n't true\" in qtext_orig) or (\"untrue\" in qtext_orig):\n",
    "      if (\"not false\" in qtext_orig) or (\"n't false\" in qtext_orig):\n",
    "          inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "      else:\n",
    "          inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание НЕ СООТВЕТСТВУЕТ тексту? \"\n",
    "  else:\n",
    "      inp += example['article_ru'] + \" \" + \"ВОПРОС: Какое высказывание СООТВЕТСТВУЕТ тексту? \"\n",
    "\n",
    "  inp += f'ПРАВИЛЬНЫЙ ОТВЕТ: \"{right_answer}\".'\n",
    "  inp += 'НЕПРАВИЛЬНЫЕ ВАРИАНТЫ ОТВЕТА: '\n",
    "\n",
    "  options = example[\"options_ru\"]\n",
    "  options = [\n",
    "      option.replace('\"', \"'\") for option in options if option != right_answer\n",
    "  ]\n",
    "  options = [\n",
    "      f'\"{option}\"' for option in options\n",
    "  ]\n",
    "  label = \"; \".join(options)\n",
    "    \n",
    "  return {\"inp\": inp, \"distractors\": label}\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"inp\"]\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"distractors\"]\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44bdce1b-cead-42f9-8bc3-424a249431eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d5e026fbff4f30ac8637cd60c9c125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98f6d2f36924296bd94e124faeaf434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd3c9a614904232bc53e81765df4496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_dataset_train = tf_dataset_train.map(to_new_format)\n",
    "tf_dataset_val = tf_dataset_val.map(to_new_format)\n",
    "tf_dataset_test = tf_dataset_test.map(to_new_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55d10c3-044c-40ad-a8fd-76eae3e557cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3524e7eb55a842f296c8b39b032c2621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f1b0c4881e421190d88f5f5d5c36c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e714a6941ce4a108efbb044bda1b2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_dataset_train = tf_dataset_train.map(preprocess_function, batched=True, batch_size=2)\n",
    "tf_dataset_val = tf_dataset_val.map(preprocess_function, batched=True, batch_size=2)\n",
    "tf_dataset_test = tf_dataset_test.map(preprocess_function, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1657b123-fcb7-4e95-8570-cba90001f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 1\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "MODEL_NAME=\"RuT5-RACE-tf-1\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\", save_strategy=\"epoch\",\n",
    "    # evaluation_strategy=\"steps\", eval_steps=100, save_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    prediction_loss_only=False,\n",
    "    gradient_checkpointing=True,\n",
    "    predict_with_generate=True, fp16=True,\n",
    "    eval_accumulation_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b4b4e3-3b58-4808-b94d-1a69a4153364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49,\n",
       " 28162,\n",
       " 5442,\n",
       " 1262,\n",
       " 1740,\n",
       " 1543,\n",
       " 314,\n",
       " 7225,\n",
       " 9773,\n",
       " 4,\n",
       " 13386,\n",
       " 49,\n",
       " 4468,\n",
       " 425,\n",
       " 4550,\n",
       " 151,\n",
       " 6935,\n",
       " 3061,\n",
       " 3,\n",
       " 110,\n",
       " 296,\n",
       " 69,\n",
       " 688,\n",
       " 188,\n",
       " 4,\n",
       " 13386,\n",
       " 49,\n",
       " 517,\n",
       " 1543,\n",
       " 2352,\n",
       " 13,\n",
       " 2080,\n",
       " 4406,\n",
       " 4,\n",
       " 83,\n",
       " 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset_val[0][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35fde12-206c-4d02-9fd0-c52cddd18677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_values(output: list[str], label_batch: list[str]) -> dict[str, Any]:\n",
    "    metric_dict = {\n",
    "        \"bleu\": bleu4.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"sbleu\": sbleu.compute(predictions=output, references=[[label] for label in label_batch]),\n",
    "        \"rouge\": rouge.compute(predictions=output, references=label_batch),\n",
    "        \"meteor\": meteor.compute(predictions=output, references=label_batch)\n",
    "    }\n",
    "    return metric_dict\n",
    "\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict[str, Any]:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels > 0, labels, tokenizer.pad_token_id)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    preds = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in preds\n",
    "    ]\n",
    "    labels = [\n",
    "        sent.replace(\"<pad>\", \" \").replace(\"</s>\", \" \").strip() for sent in labels\n",
    "    ]\n",
    "\n",
    "    metrics = compute_metric_values(preds, labels)\n",
    "    metric_dict = {\n",
    "        \"bleu\": metrics[\"bleu\"][\"bleu\"],\n",
    "        \"sbleu\": metrics[\"sbleu\"][\"score\"],\n",
    "        \"rouge1\": metrics[\"rouge\"][\"rouge1\"],\n",
    "        \"rouge2\": metrics[\"rouge\"][\"rouge2\"],\n",
    "        \"rougeL\": metrics[\"rouge\"][\"rougeL\"],\n",
    "        \"rougeLsum\": metrics[\"rouge\"][\"rougeLsum\"],\n",
    "        \"meteor\": metrics[\"meteor\"][\"meteor\"]\n",
    "    }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551f8e0c-aba1-41a8-86e7-76460caf16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46f1812-c690-4aa3-a491-64a98fb117af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tf_dataset_train,\n",
    "    eval_dataset=tf_dataset_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92450a-57ca-41ac-9d99-c5c465aeb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16441' max='65760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16441/65760 1:13:08 < 3:39:24, 3.75 it/s, Epoch 5/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Sbleu</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.381300</td>\n",
       "      <td>2.010943</td>\n",
       "      <td>0.059092</td>\n",
       "      <td>5.909222</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014921</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.186060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.003800</td>\n",
       "      <td>1.970030</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>5.754616</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.014921</td>\n",
       "      <td>0.186020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.792700</td>\n",
       "      <td>1.982938</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>6.324499</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.191351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.503300</td>\n",
       "      <td>2.052280</td>\n",
       "      <td>0.058028</td>\n",
       "      <td>5.802785</td>\n",
       "      <td>0.016852</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.185798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 47/175 00:27 < 01:17, 1.65 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/user/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
